{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.callbacks as cb \n",
    "import h5py\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image as Image, PIL.ImageDraw as ImageDraw, PIL.ImageFont as ImageFont\n",
    "import sklearn.metrics\n",
    "import scipy.special"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_gen = np.random.RandomState(41)\n",
    "\n",
    "HEIGHT = 137\n",
    "WIDTH = 236\n",
    "\n",
    "VALIDATION_SPLIT = 98\n",
    "TEST_SPLIT = 99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To deal with dataset we need to have train/val/test datasets in hdf5 files\n",
    "use cases:\n",
    "\n",
    "1. local/colab testing and architecture tuning - train on train, then validate on val and measure final score on test\n",
    "2. while training final model for submittion - mixup all 3 \n",
    "3. while ensembling - use val as train for ensemble and test to verify score\n",
    "\n",
    "\n",
    "4. would be nice to keep class distibution across the datasets, but this can be done later\n",
    "\n",
    "hdf format is 2 datasets, 1st with pictures, 2nd with labels (same shape across 1 axis)\n",
    "split size for train could be the same as original files, excluding test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_files = [str.format('Data/bengaliai-cv19/train_image_data_{0}.parquet',i) for i in range(4) ]\n",
    "\n",
    "\n",
    "# train_df = pd.read_csv('Data/bengaliai-cv19/train.csv')\n",
    "# y_labels = train_df.image_id.copy()\n",
    "# y_1 = pd.get_dummies(train_df.vowel_diacritic).values\n",
    "# y_2 = pd.get_dummies(train_df.grapheme_root).values\n",
    "# y_3 = pd.get_dummies(train_df.consonant_diacritic).values\n",
    "# y = np.hstack([y_1,y_2,y_3])\n",
    "# assert(y.shape[1]==11+168+7)\n",
    "# del train_df, y_1,y_2,y_3\n",
    "# gc.collect()\n",
    "# assert (y_labels.shape[0]==y.shape[0])\n",
    "# n_samples = y.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "at this point we know the whole DS contains y.shape[0] = y_labels.shape[0] examples and we can split those accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffled_indexes = rand_gen.permutation(y.shape[0])\n",
    "# train_indexes = shuffled_indexes[:n_samples*VALIDATION_SPLIT//100]\n",
    "# valid_indexes = shuffled_indexes[n_samples*VALIDATION_SPLIT//100:n_samples*TEST_SPLIT//100]\n",
    "# test_indexes  = shuffled_indexes[n_samples*TEST_SPLIT//100:]\n",
    "\n",
    "# valid_images = []\n",
    "# valid_labels = []\n",
    "# test_images = []\n",
    "# test_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(4):\n",
    "#     chunk_train_indexes = np.compress((train_indexes>=i*50210) & (train_indexes<(i+1)*50210),train_indexes)\n",
    "#     chunk_valid_indexes = np.compress((valid_indexes>=i*50210) & (valid_indexes<(i+1)*50210),valid_indexes)\n",
    "#     chunk_test_indexes = np.compress((test_indexes>=i*50210) & (test_indexes<(i+1)*50210),test_indexes)\n",
    "\n",
    "#     print('loading '+train_files[i])\n",
    "#     images = pd.read_parquet(train_files[i])\n",
    "#     # we'd better use numpy indexing instead of combining numpy and pandas (not sure they are 100% consistent)\n",
    "#     # float 16 is enough to save from parquet to hdf5\n",
    "#     all_chunk_images = images.iloc[:,1:].values.astype(np.float16).reshape(-1, HEIGHT, WIDTH)/255.0\n",
    "#     del images\n",
    "#     gc.collect()\n",
    "\n",
    "#     # saving train, split by 2 files each\n",
    "    \n",
    "#     train_chunk_images = all_chunk_images[chunk_train_indexes-50210*i] # train\n",
    "#     train_y_chuck = y[chunk_train_indexes]\n",
    "#     assert(train_y_chuck.shape[0]==train_chunk_images.shape[0])\n",
    "    \n",
    "#     train_split_idx = train_y_chuck.shape[0]//2\n",
    "\n",
    "#     ## Not dry, but can live with it, as it's one time thing\n",
    "#     train_chunk_0_fname = str.format('Data/bengaliai-cv19/train_image_data_processed{0}.hdf5',2*i)\n",
    "#     h5f = h5py.File(train_chunk_0_fname, 'w')\n",
    "#     h5f.create_dataset('images', data = train_chunk_images[:train_split_idx])\n",
    "#     h5f.create_dataset('labels', data = train_y_chuck[:train_split_idx])\n",
    "#     h5f.close()\n",
    "#     print('saved '+train_chunk_0_fname)\n",
    "\n",
    "#     train_chunk_1_fname = str.format('Data/bengaliai-cv19/train_image_data_processed{0}.hdf5',2*i+1)\n",
    "#     h5f = h5py.File(train_chunk_1_fname, 'w')\n",
    "#     h5f.create_dataset('images', data = train_chunk_images[train_split_idx:])\n",
    "#     h5f.create_dataset('labels', data = train_y_chuck[train_split_idx:])\n",
    "#     h5f.close()\n",
    "#     print('saved '+train_chunk_1_fname)\n",
    "\n",
    "\n",
    "#     ## for reading - \n",
    "#     # In [10]: h5f = h5py.File('data.h5','r')\n",
    "#     # In [11]: b = h5f['dataset_1'][:]\n",
    "#     # In [12]: h5f.close()\n",
    "\n",
    "#     chunk_valid_images = all_chunk_images[chunk_valid_indexes-50210*i] # valid\n",
    "#     chunk_valid_labels = y[chunk_valid_indexes]\n",
    "#     assert(chunk_valid_labels.shape[0]==chunk_valid_images.shape[0])\n",
    "#     valid_images.append(chunk_valid_images)\n",
    "#     valid_labels.append(chunk_valid_labels)\n",
    "\n",
    "#     chunk_test_images = all_chunk_images[chunk_test_indexes-50210*i] # test\n",
    "#     chunk_test_labels = y[chunk_test_indexes]\n",
    "#     assert(chunk_test_labels.shape[0]==chunk_test_images.shape[0])\n",
    "#     test_images.append(chunk_test_images)\n",
    "#     test_labels.append(chunk_test_labels)\n",
    "\n",
    "#     del train_chunk_images, train_y_chuck\n",
    "#     gc.collect()\n",
    "#     print('completed '+train_files[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving valid and test \n",
    "\n",
    "# valid_images_all = np.vstack(valid_images)\n",
    "# valid_labels_all = np.vstack(valid_labels)\n",
    "# test_images_all = np.vstack(test_images)\n",
    "# test_labels_all = np.vstack(test_labels)\n",
    "\n",
    "# ## Not dry, but can live with it, as it's one time thing\n",
    "# h5f = h5py.File('Data/bengaliai-cv19/valid_image_data_processed.hdf5', 'w')\n",
    "# h5f.create_dataset('images', data = valid_images_all)\n",
    "# h5f.create_dataset('labels', data = valid_labels_all)\n",
    "# h5f.close()\n",
    "\n",
    "# h5f = h5py.File('Data/bengaliai-cv19/test_image_data_processed.hdf5', 'w')\n",
    "# h5f.create_dataset('images', data = test_images_all)\n",
    "# h5f.create_dataset('labels', data = test_labels_all)\n",
    "# h5f.close()\n",
    "\n",
    "# del valid_images,valid_labels,test_images,test_labels\n",
    "# del valid_images_all,valid_labels_all,test_images_all,test_labels_all\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def images_generator(batch_size, shuffle=True, scale_range = [0.8,0.9,1.0,1.1,1.2], rotate_range=[-10,0,10]):    \n",
    "    files = [str.format('Data/bengaliai-cv19/train_image_data_processed{0}.hdf5',i) for i in range(8) ]\n",
    "    current_file_idx = 0\n",
    "    already_send = 0     \n",
    "    steps = 0\n",
    "    center = ( HEIGHT / 2, WIDTH/ 2)\n",
    "    \n",
    "    while True:\n",
    "        h5f = h5py.File(files[current_file_idx],'r')\n",
    "        train_X = (h5f['images'][:]).astype('float32')\n",
    "        train_Y = h5f['labels'][:]\n",
    "        h5f.close()        \n",
    "        \n",
    "        while (already_send<train_X.shape[0]):\n",
    "            if (already_send+batch_size<train_X.shape[0]):\n",
    "                train_batch_X = train_X[already_send:already_send+batch_size,:]\n",
    "                train_batch_Y = train_Y[already_send:already_send+batch_size,:]\n",
    "            else:\n",
    "                train_batch_X = train_X[already_send:,:]\n",
    "                train_batch_Y = train_Y[already_send:,:]\n",
    "            assert (train_batch_X.shape[0]==train_batch_Y.shape[0])\n",
    "            \n",
    "            train_batch_X_aug = np.array(train_batch_X,dtype='float32')\n",
    "            \n",
    "            for b in range(train_batch_X.shape[0]):\n",
    "                scale = np.random.choice(scale_range)\n",
    "                angle = np.random.choice(rotate_range)\n",
    "                M=cv2.getRotationMatrix2D(center, angle, scale)                \n",
    "                train_batch_X_aug[b]=cv2.warpAffine(train_batch_X[b], M, (WIDTH,HEIGHT),  borderValue=1.0)            \n",
    "            \n",
    "            assert (train_batch_X_aug.shape[0]==train_batch_Y.shape[0])\n",
    "            steps+=1            \n",
    "            yield np.expand_dims(train_batch_X_aug,axis=3), train_batch_Y\n",
    "            already_send+=batch_size\n",
    "        already_send=0\n",
    "        current_file_idx+=1\n",
    "        if (current_file_idx==8):\n",
    "            current_file_idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test generator\n",
    "# cnt = 0\n",
    "# batch_size = 5\n",
    "# f, ax = plt.subplots(5, 5, figsize=(16, 8))\n",
    "# ax = ax.flatten()\n",
    "\n",
    "# for i in images_generator(1):\n",
    "#     ax[cnt].imshow(np.squeeze((i[0][0]*255).astype(int)) , cmap='Greys')\n",
    "#     cnt+=1\n",
    "#     if cnt>=25:\n",
    "#         break;\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_file_name = 'Data/bengaliai-cv19/valid_image_data_processed.hdf5'\n",
    "h5f = h5py.File(valid_file_name,'r')\n",
    "valid_X = np.expand_dims(h5f['images'][:],axis=3)\n",
    "valid_Y = h5f['labels'][:]\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    '''\n",
    "    Constructs the ML model used to predict handwritten digits.\n",
    "    Taken from https://github.com/tensorflow/models/blob/master/official/vision/image_classification/mnist_main.py\n",
    "    '''\n",
    "    image = tf.keras.layers.Input(shape=(137, 236, 1))\n",
    "    y = tf.keras.layers.Conv2D(filters=32,\n",
    "                             kernel_size=5,\n",
    "                             padding='same',\n",
    "                             activation='relu')(image)\n",
    "\n",
    "    y = tf.keras.layers.MaxPooling2D(pool_size=(2, 2),\n",
    "                                   strides=(2, 2),\n",
    "                                   padding='same')(y)\n",
    "    \n",
    "    y = tf.keras.layers.Conv2D(filters=32,\n",
    "                             kernel_size=5,\n",
    "                             padding='same',\n",
    "                             activation='relu')(y)\n",
    "    \n",
    "    y = tf.keras.layers.MaxPooling2D(pool_size=(2, 2),\n",
    "                                   strides=(2, 2),\n",
    "                                   padding='same')(y)\n",
    "    y = tf.keras.layers.Flatten()(y)\n",
    "    y = tf.keras.layers.Dense(1024, activation='relu')(y)\n",
    "    y = tf.keras.layers.Dropout(0.4)(y)\n",
    "    \n",
    "    out_0 = tf.keras.layers.Dense(11, activation='softmax')(y)\n",
    "    out_1 = tf.keras.layers.Dense(168, activation='softmax')(y)\n",
    "    out_2 = tf.keras.layers.Dense(7, activation='softmax')(y)\n",
    "    \n",
    "    out_m=tf.concat(values=[out_0,out_1,out_2],axis=1)\n",
    "        \n",
    "    model = tf.keras.models.Model(image, out_m, name='bengali')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "def build_inception_model():\n",
    "    \n",
    "    img_input = keras.layers.Input(shape=(HEIGHT,WIDTH,1))\n",
    "    inception_model_def = InceptionV3(include_top=False, input_tensor=img_input,weights=None)\n",
    "    #Adding custom Layers \n",
    "    y = inception_model_def.output\n",
    "    y = tf.keras.layers.GlobalAveragePooling2D(name='avg_pool')(y)\n",
    "    y = tf.keras.layers.Dense(1024, activation='softmax', name='predictions')(y)\n",
    "    y = tf.keras.layers.Dropout(0.4)(y)\n",
    "    \n",
    "    out_0 = tf.keras.layers.Dense(11, activation='softmax')(y)\n",
    "    out_1 = tf.keras.layers.Dense(168, activation='softmax')(y)\n",
    "    out_2 = tf.keras.layers.Dense(7, activation='softmax')(y)\n",
    "    \n",
    "    out_m=tf.concat(values=[out_0,out_1,out_2],axis=1)\n",
    "\n",
    "    inception_model = tf.keras.models.Model(img_input, out_m, name='inception_bengali')\n",
    "    \n",
    "    return inception_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inception_model = build_inception_model()\n",
    "# # compile the model \n",
    "# inception_model.compile(\n",
    "#                     optimizer = keras.optimizers.Adam(),\n",
    "# #     optimizer = tf.keras.optimizers.SGD(lr=0.0001, momentum=0.9),\n",
    "#                     loss = tf.keras.losses.binary_crossentropy,\n",
    "#                     metrics=['binary_accuracy',tf.keras.metrics.Recall(name='recall')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Callbacks reused from \n",
    "# # https://www.kaggle.com/deshwalmahesh/bengali-ai-complete-beginner-tutorial-95-acc\n",
    "\n",
    "# model_fname_inception = 'models/inception_model-' + datetime.datetime.now().strftime('%Y-%m-%d-%H-%M')\n",
    "# # then go to callback definitions and run \n",
    "\n",
    "# R_LR_P = cb.ReduceLROnPlateau(monitor='val_recall',patience=3,verbose=1,factor=0.5,min_lr=0.00001,mode='max')\n",
    "# # if validation loss of out_1 is not decreasing for 3 consecutive epochs, decrease the learning rate by 0.5 \n",
    "# # given if learning rate is above 0.00001 and give us little insight on what has happened verbose=1\n",
    "\n",
    "# ES = cb.EarlyStopping(monitor='val_recall',patience=4, min_delta=0.0025,mode='max')\n",
    "# # stop the model from fitting data if validation loss has not decreased by 0.0025 in the last 5 epochs\n",
    "\n",
    "# MCP = cb.ModelCheckpoint(model_fname_inception+'.hdf5', monitor ='val_recall', verbose =1, \n",
    "#                       save_best_only = True, save_weights_only=True,mode='max')\n",
    "# # save the weights in a file name specified only if the validation loss of out_1 layer has improved from \n",
    "# # last save. out_1 because it's recall matters twice \n",
    "\n",
    "# callbacks = [R_LR_P,ES,MCP]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = inception_model.fit(\n",
    "#       images_generator(batch_size=64),\n",
    "#       epochs=30,\n",
    "#       steps_per_epoch=3080,\n",
    "#       validation_data = (valid_X, valid_Y),\n",
    "#       callbacks=callbacks\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.applications.vgg16 import VGG16\n",
    "\n",
    "def build_vgg16_model():    \n",
    "    img_input = keras.layers.Input(shape=(HEIGHT,WIDTH,1))\n",
    "    \n",
    "#     vgg16_model_def = VGG16(include_top=False, input_tensor=img_input,weights=None)\n",
    "    #Adding custom Layers \n",
    "#     y = vgg16_model_def.output\n",
    "    # Block 1\n",
    "    x = keras.layers.Conv2D(64, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block1_conv1')(img_input)\n",
    "    x = keras.layers.Conv2D(64, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block1_conv2')(x)\n",
    "    x = keras.layers.MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
    "\n",
    "    # Block 2\n",
    "    x = keras.layers.Conv2D(128, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block2_conv1')(x)\n",
    "    x = keras.layers.Conv2D(128, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block2_conv2')(x)\n",
    "    x = keras.layers.MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
    "\n",
    "    # Block 3\n",
    "    x = keras.layers.Conv2D(256, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block3_conv1')(x)\n",
    "    x = keras.layers.Conv2D(256, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block3_conv2')(x)\n",
    "    x = keras.layers.Conv2D(256, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block3_conv3')(x)\n",
    "    x = keras.layers.MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
    "\n",
    "    # Block 4\n",
    "    x = keras.layers.Conv2D(512, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block4_conv1')(x)\n",
    "    x = keras.layers.Conv2D(512, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block4_conv2')(x)\n",
    "    x = keras.layers.Conv2D(512, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block4_conv3')(x)\n",
    "    x = keras.layers.MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
    "\n",
    "    # Block 5\n",
    "    x = keras.layers.Conv2D(512, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block5_conv1')(x)\n",
    "    x = keras.layers.Conv2D(512, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block5_conv2')(x)\n",
    "    x = keras.layers.Conv2D(512, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block5_conv3')(x)\n",
    "    x = keras.layers.MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n",
    "    \n",
    "    # x->y\n",
    "    y = tf.keras.layers.GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "    \n",
    "    y = tf.keras.layers.Dense(4096, activation='softmax', name='predictions')(y)\n",
    "#     y = tf.keras.layers.Dropout(0.4)(y)\n",
    "    \n",
    "    out_0 = tf.keras.layers.Dense(11, activation='softmax')(y)\n",
    "    out_1 = tf.keras.layers.Dense(168, activation='softmax')(y)\n",
    "    out_2 = tf.keras.layers.Dense(7, activation='softmax')(y)\n",
    "    \n",
    "    out_m=tf.concat(values=[out_0,out_1,out_2],axis=1)\n",
    "\n",
    "    vgg16_model = tf.keras.models.Model(img_input, out_m, name='vgg16_bengali')\n",
    "    \n",
    "    return vgg16_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_model = build_vgg16_model()\n",
    "# compile the model \n",
    "vgg16_model.compile(\n",
    "                    optimizer = keras.optimizers.Adam(),\n",
    "#     optimizer = tf.keras.optimizers.SGD(lr=0.0001, momentum=0.9),\n",
    "#                     loss = tf.keras.losses.binary_crossentropy,\n",
    "                    loss = tf.keras.losses.categorical_crossentropy,\n",
    "                    metrics=['binary_accuracy',tf.keras.metrics.Recall(name='recall')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 3080 steps, validate on 2008 samples\n",
      "Epoch 1/30\n",
      "   4/3080 [..............................] - ETA: 13:06:24 - loss: 12.7600 - binary_accuracy: 0.9839 - recall: 0.0000e+00WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_recall` which is not available. Available metrics are: binary_accuracy,recall,lr,loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_recall` which is not available. Available metrics are: binary_accuracy,recall,lr,loss\n",
      "WARNING:tensorflow:Can save best model only with val_recall available, skipping.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-40e2dc67abbf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m       \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3080\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m       \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvalid_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_Y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m       \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m )\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    485\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1141\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Callbacks reused from \n",
    "# https://www.kaggle.com/deshwalmahesh/bengali-ai-complete-beginner-tutorial-95-acc\n",
    "\n",
    "model_fname_vgg16 = 'models/vgg16_model-' + datetime.datetime.now().strftime('%Y-%m-%d-%H-%M')\n",
    "# then go to callback definitions and run \n",
    "\n",
    "R_LR_P = cb.ReduceLROnPlateau(monitor='val_recall',patience=3,verbose=1,factor=0.5,min_lr=0.00001,mode='max')\n",
    "# if validation loss of out_1 is not decreasing for 3 consecutive epochs, decrease the learning rate by 0.5 \n",
    "# given if learning rate is above 0.00001 and give us little insight on what has happened verbose=1\n",
    "\n",
    "ES = cb.EarlyStopping(monitor='val_recall',patience=4, min_delta=0.0025,mode='max')\n",
    "# stop the model from fitting data if validation loss has not decreased by 0.0025 in the last 5 epochs\n",
    "\n",
    "MCP = cb.ModelCheckpoint(model_fname_vgg16+'.hdf5', monitor ='val_recall', verbose =1, \n",
    "                      save_best_only = True, save_weights_only=True,mode='max')\n",
    "# save the weights in a file name specified only if the validation loss of out_1 layer has improved from \n",
    "# last save. out_1 because it's recall matters twice \n",
    "\n",
    "callbacks = [R_LR_P,ES,MCP]\n",
    "\n",
    "history = vgg16_model.fit(\n",
    "      images_generator(batch_size=64),\n",
    "      epochs=30,\n",
    "      steps_per_epoch=3080,\n",
    "      validation_data = (valid_X, valid_Y),\n",
    "      callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = vgg16_model.to_json()\n",
    "with open(model_fname_vgg16+'.json', \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def customLoss(yTrue,yPred):\n",
    "#     return keras.losses.categorical_crossentropy(yTrue[:,0:11],yPred[:,0:11])+\\\n",
    "#         2*keras.losses.categorical_crossentropy(yTrue[:,11:179],yPred[:,11:179])+\\\n",
    "#         keras.losses.categorical_crossentropy(yTrue[:,179:186],yPred[:,179:186])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # https://stackoverflow.com/questions/43076609/how-to-calculate-precision-and-recall-in-keras \n",
    "# # -> https://github.com/keras-team/keras/commit/a56b1a55182acf061b1eb2e2c86b48193a0e88f7\n",
    "\n",
    "# def recall(y_true, y_pred):\n",
    "#     \"\"\"Recall metric.\n",
    "#     Only computes a batch-wise average of recall.\n",
    "#     Computes the recall, a metric for multi-label classification of\n",
    "#     how many relevant items are selected.\n",
    "#     \"\"\"\n",
    "#     true_positives = keras.backend.sum(keras.backend.round(keras.backend.clip(y_true * y_pred, 0, 1)))\n",
    "#     possible_positives = keras.backend.sum(keras.backend.round(keras.backend.clip(y_true, 0, 1)))\n",
    "#     recall = true_positives / (possible_positives + keras.backend.epsilon())\n",
    "#     return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def customMetric(yTrue,yPred):\n",
    "# #     return keras.metrics.Recall(yTrue,yPred)\n",
    "#     return keras.metrics.Recall(yTrue[:,0:11],yPred[:,0:11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# customMetric(valid_Y,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "#     loss=customLoss,\n",
    "    loss = keras.losses.binary_crossentropy,\n",
    "    metrics=['binary_accuracy',keras.metrics.Recall()])\n",
    "\n",
    "model_fname = 'models/model-' + datetime.datetime.now().strftime('%Y-%m-%d-%H-%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(model_fname+'.json', \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "      images_generator(batch_size=64),\n",
    "      epochs=12,\n",
    "      steps_per_epoch=3080,\n",
    "      validation_data = (valid_X, valid_Y),\n",
    "      callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.plot(history.history['recall'])\n",
    "plt.plot(history.history['val_recall'])\n",
    "\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_fname = 'models/model-2020-01-04-11-33'\n",
    "# model_fname = 'models/model-2020-01-09-06-03'\n",
    "# model_fname = 'models/model-2020-01-12-19-19'\n",
    "model_fname = 'models/vgg16_model-2020-01-15-05-06'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate inference phase\n",
    "\n",
    "import tensorflow.keras.models\n",
    "# load json and create model\n",
    "json_file = open(model_fname+'.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = keras.models.model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(model_fname+'.hdf5')\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "# evaluate loaded model on test data\n",
    "loaded_model.compile(optimizer=keras.optimizers.Adam(),\n",
    "#     loss=customLoss,\n",
    "    loss = keras.losses.binary_crossentropy,\n",
    "    metrics=['binary_accuracy',keras.metrics.Recall()])\n",
    "score = loaded_model.evaluate(valid_X, valid_Y, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(loaded_model.metrics_names)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric from rules\n",
    "```\n",
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "\n",
    "scores = []\n",
    "for component in ['grapheme_root', 'consonant_diacritic', 'vowel_diacritic']:\n",
    "    y_true_subset = solution[solution[component] == component]['target'].values\n",
    "    y_pred_subset = submission[submission[component] == component]['target'].values\n",
    "    scores.append(sklearn.metrics.recall_score(\n",
    "        y_true_subset, y_pred_subset, average='macro'))\n",
    "final_score = np.average(scores, weights=[2,1,1])\n",
    "```\n",
    "also keep in mind target is constructed as\n",
    "```\n",
    "y_1 = pd.get_dummies(train_df.vowel_diacritic).values\n",
    "y_2 = pd.get_dummies(train_df.grapheme_root).values\n",
    "y_3 = pd.get_dummies(train_df.consonant_diacritic).values\n",
    "assert(y.shape[1]==11+168+7)\n",
    "del train_df, y_1,y_2,y_3\n",
    "```\n",
    "\n",
    "plan: \n",
    "1. get prediction on validation set\n",
    "2. try to compute metric for val set \n",
    "3. try to incorporate metric into training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=loaded_model.predict(valid_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(valid_Y.shape==predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "\n",
    "for intervals in [(0,11),(11,179),(179,186)]:    \n",
    "    y_true_subset = valid_Y[:,intervals[0]:intervals[1]]\n",
    "    y_pred_subset = predictions[:,intervals[0]:intervals[1]]\n",
    "    #\"hard\" max\n",
    "    y_pred_choice = np.zeros(y_pred_subset.shape, dtype='uint8')\n",
    "    y_pred_choice[np.arange(len(y_pred_subset)), y_pred_subset.argmax(axis=1)] = 1   \n",
    "    \n",
    "    partical_score = sklearn.metrics.recall_score(\n",
    "        y_true_subset, y_pred_choice, average='macro')\n",
    "    scores.append(partical_score)\n",
    "    \n",
    "    print('for '+str(intervals)+ ' score is '+str(partical_score))\n",
    "    \n",
    "\n",
    "final_score = np.average(scores, weights=[1,2,1])\n",
    "print()\n",
    "print('TOTAL: '+str(final_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for model-2020-01-12-19-19\n",
    "# for (0, 11) score is 0.8161456276283384\n",
    "# for (11, 179) score is 0.41152848969600087\n",
    "# for (179, 186) score is 0.6923909632987134\n",
    "\n",
    "# TOTAL: 0.5828983925797634\n",
    "\n",
    "# AND \n",
    "\n",
    "# for (0, 11) score is 0.8016213740678662\n",
    "# for (11, 179) score is 0.4136798279457808\n",
    "# for (179, 186) score is 0.7025289942805701\n",
    "\n",
    "# TOTAL: 0.5828775060599996\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outcome\n",
    "\n",
    "| Model                       |file name | Local Recall   |LB score |  Ep |Comment|\n",
    "|-----------------------------|----------|----------------|---------|-----|-----------|\n",
    "| mnist_main (186 Dense out), custom loss  | model-2020-01-09-05-43 |0.0614  |  | 6  |Seems there is a bug because keras recall doesn't equal recall per model|\n",
    "| mnist_main (186 Dense out), binary_crossenthropy loss | model-2020-01-09-06-03 |0.5828 | 0.5723 | 6 | Custom loss makes training much worse|\n",
    "| mnist_main (3x softmax out) |model-2020-01-12-19-19 | 0.5829 | N/A | 11 | Doesn't makes much sence to submit\n",
    "| vgg16 | vgg16_model-2020-01-15-05-06 | 0.0614 | N/A | 1 | Model is not training after 1 epoch (to add shuffles, augment)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
