{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import PIL.Image as Image, PIL.ImageDraw as ImageDraw, PIL.ImageFont as ImageFont\n",
    "import sklearn.metrics\n",
    "import scipy.special\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import h5py\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_gen = np.random.RandomState(41)\n",
    "\n",
    "HEIGHT = 137\n",
    "WIDTH = 236\n",
    "\n",
    "VALIDATION_SPLIT = 98\n",
    "TEST_SPLIT = 99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To deal with dataset we need to have train/val/test datasets in hdf5 files\n",
    "use cases:\n",
    "\n",
    "1. local/colab testing and architecture tuning - train on train, then validate on val and measure final score on test\n",
    "2. while training final model for submittion - mixup all 3 \n",
    "3. while ensembling - use val as train for ensemble and test to verify score\n",
    "\n",
    "\n",
    "4. would be nice to keep class distibution across the datasets, but this can be done later\n",
    "\n",
    "hdf format is 2 datasets, 1st with pictures, 2nd with labels (same shape across 1 axis)\n",
    "split size for train could be the same as original files, excluding test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_files = [str.format('Data/bengaliai-cv19/train_image_data_{0}.parquet',i) for i in range(4) ]\n",
    "\n",
    "\n",
    "# train_df = pd.read_csv('Data/bengaliai-cv19/train.csv')\n",
    "# y_labels = train_df.image_id.copy()\n",
    "# y_1 = pd.get_dummies(train_df.vowel_diacritic).values\n",
    "# y_2 = pd.get_dummies(train_df.grapheme_root).values\n",
    "# y_3 = pd.get_dummies(train_df.consonant_diacritic).values\n",
    "# y = np.hstack([y_1,y_2,y_3])\n",
    "# assert(y.shape[1]==11+168+7)\n",
    "# del train_df, y_1,y_2,y_3\n",
    "# gc.collect()\n",
    "# assert (y_labels.shape[0]==y.shape[0])\n",
    "# n_samples = y.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "at this point we know the whole DS contains y.shape[0] = y_labels.shape[0] examples and we can split those accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffled_indexes = rand_gen.permutation(y.shape[0])\n",
    "# train_indexes = shuffled_indexes[:n_samples*VALIDATION_SPLIT//100]\n",
    "# valid_indexes = shuffled_indexes[n_samples*VALIDATION_SPLIT//100:n_samples*TEST_SPLIT//100]\n",
    "# test_indexes  = shuffled_indexes[n_samples*TEST_SPLIT//100:]\n",
    "\n",
    "# valid_images = []\n",
    "# valid_labels = []\n",
    "# test_images = []\n",
    "# test_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(4):\n",
    "#     chunk_train_indexes = np.compress((train_indexes>=i*50210) & (train_indexes<(i+1)*50210),train_indexes)\n",
    "#     chunk_valid_indexes = np.compress((valid_indexes>=i*50210) & (valid_indexes<(i+1)*50210),valid_indexes)\n",
    "#     chunk_test_indexes = np.compress((test_indexes>=i*50210) & (test_indexes<(i+1)*50210),test_indexes)\n",
    "\n",
    "#     print('loading '+train_files[i])\n",
    "#     images = pd.read_parquet(train_files[i])\n",
    "#     # we'd better use numpy indexing instead of combining numpy and pandas (not sure they are 100% consistent)\n",
    "#     # float 16 is enough to save from parquet to hdf5\n",
    "#     all_chunk_images = images.iloc[:,1:].values.astype(np.float16).reshape(-1, HEIGHT, WIDTH)/255.0\n",
    "#     del images\n",
    "#     gc.collect()\n",
    "\n",
    "#     # saving train, split by 2 files each\n",
    "    \n",
    "#     train_chunk_images = all_chunk_images[chunk_train_indexes-50210*i] # train\n",
    "#     train_y_chuck = y[chunk_train_indexes]\n",
    "#     assert(train_y_chuck.shape[0]==train_chunk_images.shape[0])\n",
    "    \n",
    "#     train_split_idx = train_y_chuck.shape[0]//2\n",
    "\n",
    "#     ## Not dry, but can live with it, as it's one time thing\n",
    "#     train_chunk_0_fname = str.format('Data/bengaliai-cv19/train_image_data_processed{0}.hdf5',2*i)\n",
    "#     h5f = h5py.File(train_chunk_0_fname, 'w')\n",
    "#     h5f.create_dataset('images', data = train_chunk_images[:train_split_idx])\n",
    "#     h5f.create_dataset('labels', data = train_y_chuck[:train_split_idx])\n",
    "#     h5f.close()\n",
    "#     print('saved '+train_chunk_0_fname)\n",
    "\n",
    "#     train_chunk_1_fname = str.format('Data/bengaliai-cv19/train_image_data_processed{0}.hdf5',2*i+1)\n",
    "#     h5f = h5py.File(train_chunk_1_fname, 'w')\n",
    "#     h5f.create_dataset('images', data = train_chunk_images[train_split_idx:])\n",
    "#     h5f.create_dataset('labels', data = train_y_chuck[train_split_idx:])\n",
    "#     h5f.close()\n",
    "#     print('saved '+train_chunk_1_fname)\n",
    "\n",
    "\n",
    "#     ## for reading - \n",
    "#     # In [10]: h5f = h5py.File('data.h5','r')\n",
    "#     # In [11]: b = h5f['dataset_1'][:]\n",
    "#     # In [12]: h5f.close()\n",
    "\n",
    "#     chunk_valid_images = all_chunk_images[chunk_valid_indexes-50210*i] # valid\n",
    "#     chunk_valid_labels = y[chunk_valid_indexes]\n",
    "#     assert(chunk_valid_labels.shape[0]==chunk_valid_images.shape[0])\n",
    "#     valid_images.append(chunk_valid_images)\n",
    "#     valid_labels.append(chunk_valid_labels)\n",
    "\n",
    "#     chunk_test_images = all_chunk_images[chunk_test_indexes-50210*i] # test\n",
    "#     chunk_test_labels = y[chunk_test_indexes]\n",
    "#     assert(chunk_test_labels.shape[0]==chunk_test_images.shape[0])\n",
    "#     test_images.append(chunk_test_images)\n",
    "#     test_labels.append(chunk_test_labels)\n",
    "\n",
    "#     del train_chunk_images, train_y_chuck\n",
    "#     gc.collect()\n",
    "#     print('completed '+train_files[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving valid and test \n",
    "\n",
    "# valid_images_all = np.vstack(valid_images)\n",
    "# valid_labels_all = np.vstack(valid_labels)\n",
    "# test_images_all = np.vstack(test_images)\n",
    "# test_labels_all = np.vstack(test_labels)\n",
    "\n",
    "# ## Not dry, but can live with it, as it's one time thing\n",
    "# h5f = h5py.File('Data/bengaliai-cv19/valid_image_data_processed.hdf5', 'w')\n",
    "# h5f.create_dataset('images', data = valid_images_all)\n",
    "# h5f.create_dataset('labels', data = valid_labels_all)\n",
    "# h5f.close()\n",
    "\n",
    "# h5f = h5py.File('Data/bengaliai-cv19/test_image_data_processed.hdf5', 'w')\n",
    "# h5f.create_dataset('images', data = test_images_all)\n",
    "# h5f.create_dataset('labels', data = test_labels_all)\n",
    "# h5f.close()\n",
    "\n",
    "# del valid_images,valid_labels,test_images,test_labels\n",
    "# del valid_images_all,valid_labels_all,test_images_all,test_labels_all\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def images_generator(batch_size):\n",
    "    \n",
    "    files = [str.format('Data/bengaliai-cv19/train_image_data_processed{0}.hdf5',i) for i in range(8) ]\n",
    "    current_file_idx = 0\n",
    "    already_send = 0     \n",
    "    steps = 0\n",
    "    \n",
    "    while True:\n",
    "#     ## for reading - \n",
    "#     # In [10]: h5f = h5py.File('data.h5','r')\n",
    "#     # In [11]: b = h5f['dataset_1'][:]\n",
    "#     # In [12]: h5f.close()\n",
    "        h5f = h5py.File(files[current_file_idx],'r')\n",
    "        train_X = h5f['images'][:]\n",
    "        train_Y = h5f['labels'][:]        \n",
    "        h5f.close()        \n",
    "#         print(\"loaded \"+str(files[current_file_idx])+ \" with size \"+str(train_X.shape))        \n",
    "        \n",
    "        while (already_send<train_X.shape[0]):\n",
    "            if (already_send+batch_size<train_X.shape[0]):\n",
    "                train_batch_X = train_X[already_send:already_send+batch_size,:]\n",
    "                train_batch_Y = train_Y[already_send:already_send+batch_size,:]\n",
    "            else:\n",
    "                train_batch_X = train_X[already_send:,:]\n",
    "                train_batch_Y = train_Y[already_send:,:]\n",
    "            assert (train_batch_X.shape[0]==train_batch_Y.shape[0])                \n",
    "            steps+=1\n",
    "#             print(\"sending \"+str(already_send) + \" steps \" + str(steps))\n",
    "            \n",
    "            yield np.expand_dims(train_batch_X,axis=3), train_batch_Y\n",
    "            already_send+=batch_size\n",
    "\n",
    "#         print(\"file completed, swithing to next. Steps = \"+str(steps))\n",
    "        already_send=0\n",
    "        current_file_idx+=1\n",
    "        if (current_file_idx==8):\n",
    "            current_file_idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_file_name = 'Data/bengaliai-cv19/valid_image_data_processed.hdf5'\n",
    "h5f = h5py.File(valid_file_name,'r')\n",
    "valid_X = np.expand_dims(h5f['images'][:],axis=3)\n",
    "valid_Y = h5f['labels'][:]\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    '''\n",
    "    Constructs the ML model used to predict handwritten digits.\n",
    "    Taken from https://github.com/tensorflow/models/blob/master/official/vision/image_classification/mnist_main.py\n",
    "    '''\n",
    "    image = tf.keras.layers.Input(shape=(137, 236, 1))\n",
    "    y = tf.keras.layers.Conv2D(filters=32,\n",
    "                             kernel_size=5,\n",
    "                             padding='same',\n",
    "                             activation='relu')(image)\n",
    "\n",
    "    y = tf.keras.layers.MaxPooling2D(pool_size=(2, 2),\n",
    "                                   strides=(2, 2),\n",
    "                                   padding='same')(y)\n",
    "    \n",
    "    y = tf.keras.layers.Conv2D(filters=32,\n",
    "                             kernel_size=5,\n",
    "                             padding='same',\n",
    "                             activation='relu')(y)\n",
    "    \n",
    "    y = tf.keras.layers.MaxPooling2D(pool_size=(2, 2),\n",
    "                                   strides=(2, 2),\n",
    "                                   padding='same')(y)\n",
    "    y = tf.keras.layers.Flatten()(y)\n",
    "    y = tf.keras.layers.Dense(1024, activation='relu')(y)\n",
    "    y = tf.keras.layers.Dropout(0.4)(y)\n",
    "    \n",
    "#     out_m = tf.keras.layers.Dense(186, activation='sigmoid')(y)\n",
    "    \n",
    "    out_0 = tf.keras.layers.Dense(11, activation='softmax')(y)\n",
    "    out_1 = tf.keras.layers.Dense(168, activation='softmax')(y)\n",
    "    out_2 = tf.keras.layers.Dense(7, activation='softmax')(y)\n",
    "    \n",
    "    out_m=tf.concat(values=[out_0,out_1,out_2],axis=1)\n",
    "        \n",
    "#         # vowel_diacritic\n",
    "#         self.fc1 = nn.Linear(512,11)\n",
    "#         # grapheme_root\n",
    "#         self.fc2 = nn.Linear(512,168)\n",
    "#         # consonant_diacritic\n",
    "#         self.fc3 = nn.Linear(512,7)\n",
    "\n",
    "#     probs = tf.keras.layers.Dense(10, activation='softmax')(y)\n",
    "\n",
    "#      Idea of multiclass classification from the link below - replace activation with sigmoid\n",
    "#    loss=\"binary_crossentropy\", metrics=[\"accuracy\"]\n",
    "#     https://www.pyimagesearch.com/2018/05/07/multi-label-classification-with-keras/\n",
    "\n",
    "    model = tf.keras.models.Model(image, out_m, name='bengali')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = model.fit(\n",
    "#       np.expand_dims(X_train,axis=3),y_train,\n",
    "#       epochs=3,\n",
    "#       batch_size=64,\n",
    "#       validation_data=(np.expand_dims(X_test,axis=3),y_test)\n",
    "# #       steps_per_epoch=train_steps,\n",
    "# #       callbacks=callbacks,\n",
    "# #       validation_steps=num_eval_steps,\n",
    "# #       validation_data=eval_input_dataset,\n",
    "# #       validation_freq=flags_obj.epochs_between_evals\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def customLoss(yTrue,yPred):\n",
    "#     return keras.losses.categorical_crossentropy(yTrue[:,0:11],yPred[:,0:11])+\\\n",
    "#         2*keras.losses.categorical_crossentropy(yTrue[:,11:179],yPred[:,11:179])+\\\n",
    "#         keras.losses.categorical_crossentropy(yTrue[:,179:186],yPred[:,179:186])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # https://stackoverflow.com/questions/43076609/how-to-calculate-precision-and-recall-in-keras \n",
    "# # -> https://github.com/keras-team/keras/commit/a56b1a55182acf061b1eb2e2c86b48193a0e88f7\n",
    "\n",
    "# def recall(y_true, y_pred):\n",
    "#     \"\"\"Recall metric.\n",
    "#     Only computes a batch-wise average of recall.\n",
    "#     Computes the recall, a metric for multi-label classification of\n",
    "#     how many relevant items are selected.\n",
    "#     \"\"\"\n",
    "#     true_positives = keras.backend.sum(keras.backend.round(keras.backend.clip(y_true * y_pred, 0, 1)))\n",
    "#     possible_positives = keras.backend.sum(keras.backend.round(keras.backend.clip(y_true, 0, 1)))\n",
    "#     recall = true_positives / (possible_positives + keras.backend.epsilon())\n",
    "#     return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def customMetric(yTrue,yPred):\n",
    "# #     return keras.metrics.Recall(yTrue,yPred)\n",
    "#     return keras.metrics.Recall(yTrue[:,0:11],yPred[:,0:11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# customMetric(valid_Y,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "#     loss=customLoss,\n",
    "    loss = keras.losses.binary_crossentropy,\n",
    "    metrics=['binary_accuracy',keras.metrics.Recall()])\n",
    "\n",
    "model_fname = 'models/model-' + datetime.datetime.now().strftime('%Y-%m-%d-%H-%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'recall'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics[1].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks reused from \n",
    "# https://www.kaggle.com/deshwalmahesh/bengali-ai-complete-beginner-tutorial-95-acc\n",
    "    \n",
    "import tensorflow.keras.callbacks as cb \n",
    "\n",
    "R_LR_P = cb.ReduceLROnPlateau(monitor='val_recall',patience=3,verbose=1,factor=0.5,min_lr=0.00001,mode='max')\n",
    "# if validation loss of out_1 is not decreasing for 3 consecutive epochs, decrease the learning rate by 0.5 \n",
    "# given if learning rate is above 0.00001 and give us little insight on what has happened verbose=1\n",
    "\n",
    "ES = cb.EarlyStopping(monitor='val_recall',patience=4, min_delta=0.0025,mode='max')\n",
    "# stop the model from fitting data if validation loss has not decreased by 0.0025 in the last 5 epochs\n",
    "\n",
    "MCP = cb.ModelCheckpoint(model_fname+'.hdf5', monitor ='val_recall', verbose =1, \n",
    "                      save_best_only = True, save_weights_only=True,mode='max')\n",
    "# save the weights in a file name specified only if the validation loss of out_1 layer has improved from \n",
    "# last save. out_1 because it's recall matters twice \n",
    "\n",
    "callbacks = [R_LR_P,ES,MCP]\n",
    "\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(model_fname+'.json', \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "3078/3080 [============================>.] - ETA: 0s - loss: 0.0430 - binary_accuracy: 0.9884 - recall: 0.4016Epoch 1/12\n",
      "2008/3080 [==================>...........] - ETA: 0s - loss: 0.0348 - binary_accuracy: 0.9901 - recall: 0.4875\n",
      "Epoch 00001: val_recall improved from -inf to 0.48755, saving model to models/model-2020-01-12-19-19.hdf5\n",
      "3080/3080 [==============================] - 139s 45ms/step - loss: 0.0430 - binary_accuracy: 0.9884 - recall: 0.4016 - val_loss: 0.0348 - val_binary_accuracy: 0.9901 - val_recall: 0.4875\n",
      "Epoch 2/12\n",
      "3078/3080 [============================>.] - ETA: 0s - loss: 0.0326 - binary_accuracy: 0.9904 - recall: 0.5192Epoch 1/12\n",
      "1968/3080 [==================>...........] - ETA: 0s - loss: 0.0273 - binary_accuracy: 0.9916 - recall: 0.5732\n",
      "Epoch 00002: val_recall improved from 0.48755 to 0.57337, saving model to models/model-2020-01-12-19-19.hdf5\n",
      "3080/3080 [==============================] - 131s 43ms/step - loss: 0.0326 - binary_accuracy: 0.9904 - recall: 0.5192 - val_loss: 0.0273 - val_binary_accuracy: 0.9916 - val_recall: 0.5734\n",
      "Epoch 3/12\n",
      "3078/3080 [============================>.] - ETA: 0s - loss: 0.0278 - binary_accuracy: 0.9914 - recall: 0.5782Epoch 1/12\n",
      "1952/3080 [==================>...........] - ETA: 0s - loss: 0.0249 - binary_accuracy: 0.9922 - recall: 0.6081\n",
      "Epoch 00003: val_recall improved from 0.57337 to 0.60840, saving model to models/model-2020-01-12-19-19.hdf5\n",
      "3080/3080 [==============================] - 131s 42ms/step - loss: 0.0278 - binary_accuracy: 0.9914 - recall: 0.5782 - val_loss: 0.0248 - val_binary_accuracy: 0.9922 - val_recall: 0.6084\n",
      "Epoch 4/12\n",
      "3078/3080 [============================>.] - ETA: 0s - loss: 0.0250 - binary_accuracy: 0.9921 - recall: 0.6165Epoch 1/12\n",
      "1936/3080 [=================>............] - ETA: 0s - loss: 0.0232 - binary_accuracy: 0.9925 - recall: 0.6362\n",
      "Epoch 00004: val_recall improved from 0.60840 to 0.63679, saving model to models/model-2020-01-12-19-19.hdf5\n",
      "3080/3080 [==============================] - 131s 42ms/step - loss: 0.0250 - binary_accuracy: 0.9921 - recall: 0.6166 - val_loss: 0.0231 - val_binary_accuracy: 0.9926 - val_recall: 0.6368\n",
      "Epoch 5/12\n",
      "3078/3080 [============================>.] - ETA: 0s - loss: 0.0228 - binary_accuracy: 0.9926 - recall: 0.6493Epoch 1/12\n",
      "1920/3080 [=================>............] - ETA: 0s - loss: 0.0225 - binary_accuracy: 0.9928 - recall: 0.6552\n",
      "Epoch 00005: val_recall improved from 0.63679 to 0.65505, saving model to models/model-2020-01-12-19-19.hdf5\n",
      "3080/3080 [==============================] - 130s 42ms/step - loss: 0.0228 - binary_accuracy: 0.9926 - recall: 0.6493 - val_loss: 0.0225 - val_binary_accuracy: 0.9928 - val_recall: 0.6550\n",
      "Epoch 6/12\n",
      "3078/3080 [============================>.] - ETA: 0s - loss: 0.0208 - binary_accuracy: 0.9932 - recall: 0.6799Epoch 1/12\n",
      "1904/3080 [=================>............] - ETA: 0s - loss: 0.0224 - binary_accuracy: 0.9928 - recall: 0.6588\n",
      "Epoch 00006: val_recall improved from 0.65505 to 0.65870, saving model to models/model-2020-01-12-19-19.hdf5\n",
      "3080/3080 [==============================] - 130s 42ms/step - loss: 0.0208 - binary_accuracy: 0.9932 - recall: 0.6799 - val_loss: 0.0223 - val_binary_accuracy: 0.9927 - val_recall: 0.6587\n",
      "Epoch 7/12\n",
      "3078/3080 [============================>.] - ETA: 0s - loss: 0.0192 - binary_accuracy: 0.9936 - recall: 0.7051Epoch 1/12\n",
      "1920/3080 [=================>............] - ETA: 0s - loss: 0.0222 - binary_accuracy: 0.9929 - recall: 0.6747\n",
      "Epoch 00007: val_recall improved from 0.65870 to 0.67530, saving model to models/model-2020-01-12-19-19.hdf5\n",
      "3080/3080 [==============================] - 130s 42ms/step - loss: 0.0192 - binary_accuracy: 0.9936 - recall: 0.7052 - val_loss: 0.0221 - val_binary_accuracy: 0.9930 - val_recall: 0.6753\n",
      "Epoch 8/12\n",
      "3078/3080 [============================>.] - ETA: 0s - loss: 0.0177 - binary_accuracy: 0.9940 - recall: 0.7295Epoch 1/12\n",
      "1936/3080 [=================>............] - ETA: 0s - loss: 0.0228 - binary_accuracy: 0.9929 - recall: 0.6854\n",
      "Epoch 00008: val_recall improved from 0.67530 to 0.68625, saving model to models/model-2020-01-12-19-19.hdf5\n",
      "3080/3080 [==============================] - 132s 43ms/step - loss: 0.0177 - binary_accuracy: 0.9940 - recall: 0.7295 - val_loss: 0.0227 - val_binary_accuracy: 0.9929 - val_recall: 0.6863\n",
      "Epoch 9/12\n",
      "3078/3080 [============================>.] - ETA: 0s - loss: 0.0163 - binary_accuracy: 0.9944 - recall: 0.7506Epoch 1/12\n",
      "1984/3080 [==================>...........] - ETA: 0s - loss: 0.0228 - binary_accuracy: 0.9929 - recall: 0.6907\n",
      "Epoch 00009: val_recall improved from 0.68625 to 0.69074, saving model to models/model-2020-01-12-19-19.hdf5\n",
      "3080/3080 [==============================] - 131s 43ms/step - loss: 0.0163 - binary_accuracy: 0.9944 - recall: 0.7506 - val_loss: 0.0227 - val_binary_accuracy: 0.9929 - val_recall: 0.6907\n",
      "Epoch 10/12\n",
      "3078/3080 [============================>.] - ETA: 0s - loss: 0.0151 - binary_accuracy: 0.9948 - recall: 0.7710Epoch 1/12\n",
      "1936/3080 [=================>............] - ETA: 0s - loss: 0.0241 - binary_accuracy: 0.9929 - recall: 0.7028\n",
      "Epoch 00010: val_recall improved from 0.69074 to 0.70418, saving model to models/model-2020-01-12-19-19.hdf5\n",
      "3080/3080 [==============================] - 131s 43ms/step - loss: 0.0151 - binary_accuracy: 0.9948 - recall: 0.7710 - val_loss: 0.0239 - val_binary_accuracy: 0.9929 - val_recall: 0.7042\n",
      "Epoch 11/12\n",
      "3078/3080 [============================>.] - ETA: 0s - loss: 0.0140 - binary_accuracy: 0.9951 - recall: 0.7889Epoch 1/12\n",
      "1920/3080 [=================>............] - ETA: 0s - loss: 0.0240 - binary_accuracy: 0.9929 - recall: 0.7050\n",
      "Epoch 00011: val_recall improved from 0.70418 to 0.70551, saving model to models/model-2020-01-12-19-19.hdf5\n",
      "3080/3080 [==============================] - 131s 43ms/step - loss: 0.0140 - binary_accuracy: 0.9951 - recall: 0.7889 - val_loss: 0.0239 - val_binary_accuracy: 0.9929 - val_recall: 0.7055\n",
      "Epoch 12/12\n",
      "3078/3080 [============================>.] - ETA: 0s - loss: 0.0131 - binary_accuracy: 0.9954 - recall: 0.8036Epoch 1/12\n",
      "1952/3080 [==================>...........] - ETA: 0s - loss: 0.0247 - binary_accuracy: 0.9927 - recall: 0.7042\n",
      "Epoch 00012: val_recall did not improve from 0.70551\n",
      "3080/3080 [==============================] - 130s 42ms/step - loss: 0.0131 - binary_accuracy: 0.9954 - recall: 0.8036 - val_loss: 0.0246 - val_binary_accuracy: 0.9927 - val_recall: 0.7047\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "      images_generator(batch_size=64),\n",
    "      epochs=12,\n",
    "      steps_per_epoch=3080,\n",
    "      validation_data = (valid_X, valid_Y),\n",
    "      callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.plot(history.history['recall'])\n",
    "plt.plot(history.history['val_recall'])\n",
    "\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_fname = 'models/model-2020-01-04-11-33'\n",
    "model_fname = 'models/model-2020-01-09-06-03'\n",
    "# model_fname = 'models/model-2020-01-12-19-19'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "binary_accuracy: 99.26%\n"
     ]
    }
   ],
   "source": [
    "# Separate inference phase\n",
    "\n",
    "import tensorflow.keras.models\n",
    "# load json and create model\n",
    "json_file = open(model_fname+'.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = keras.models.model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(model_fname+'.hdf5')\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "# evaluate loaded model on test data\n",
    "loaded_model.compile(optimizer=keras.optimizers.Adam(),\n",
    "#     loss=customLoss,\n",
    "    loss = keras.losses.binary_crossentropy,\n",
    "    metrics=['binary_accuracy',keras.metrics.Recall()])\n",
    "score = loaded_model.evaluate(valid_X, valid_Y, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'binary_accuracy', 'recall_3']\n",
      "[0.024003607736700086, 0.99263954, 0.61387783]\n"
     ]
    }
   ],
   "source": [
    "print(loaded_model.metrics_names)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric from rules\n",
    "```\n",
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "\n",
    "scores = []\n",
    "for component in ['grapheme_root', 'consonant_diacritic', 'vowel_diacritic']:\n",
    "    y_true_subset = solution[solution[component] == component]['target'].values\n",
    "    y_pred_subset = submission[submission[component] == component]['target'].values\n",
    "    scores.append(sklearn.metrics.recall_score(\n",
    "        y_true_subset, y_pred_subset, average='macro'))\n",
    "final_score = np.average(scores, weights=[2,1,1])\n",
    "```\n",
    "also keep in mind target is constructed as\n",
    "```\n",
    "y_1 = pd.get_dummies(train_df.vowel_diacritic).values\n",
    "y_2 = pd.get_dummies(train_df.grapheme_root).values\n",
    "y_3 = pd.get_dummies(train_df.consonant_diacritic).values\n",
    "assert(y.shape[1]==11+168+7)\n",
    "del train_df, y_1,y_2,y_3\n",
    "```\n",
    "\n",
    "plan: \n",
    "1. get prediction on validation set\n",
    "2. try to compute metric for val set \n",
    "3. try to incorporate metric into training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=loaded_model.predict(valid_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(valid_Y.shape==predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for (0, 11) score is 0.8016213740678662\n",
      "for (11, 179) score is 0.4136798279457808\n",
      "for (179, 186) score is 0.7025289942805701\n",
      "\n",
      "TOTAL: 0.5828775060599996\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "for intervals in [(0,11),(11,179),(179,186)]:    \n",
    "    y_true_subset = valid_Y[:,intervals[0]:intervals[1]]\n",
    "    y_pred_subset = predictions[:,intervals[0]:intervals[1]]\n",
    "    #\"hard\" max\n",
    "    y_pred_choice = np.zeros(y_pred_subset.shape, dtype='uint8')\n",
    "    y_pred_choice[np.arange(len(y_pred_subset)), y_pred_subset.argmax(axis=1)] = 1   \n",
    "    \n",
    "    partical_score = sklearn.metrics.recall_score(\n",
    "        y_true_subset, y_pred_choice, average='macro')\n",
    "    scores.append(partical_score)\n",
    "    \n",
    "    print('for '+str(intervals)+ ' score is '+str(partical_score))\n",
    "    \n",
    "\n",
    "final_score = np.average(scores, weights=[1,2,1])\n",
    "print()\n",
    "print('TOTAL: '+str(final_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for (0, 11) score is 0.8161456276283384\n",
      "for (11, 179) score is 0.41152848969600087\n",
      "for (179, 186) score is 0.6923909632987134\n",
      "\n",
      "TOTAL: 0.5828983925797634\n"
     ]
    }
   ],
   "source": [
    "# for model-2020-01-12-19-19\n",
    "# for (0, 11) score is 0.8161456276283384\n",
    "# for (11, 179) score is 0.41152848969600087\n",
    "# for (179, 186) score is 0.6923909632987134\n",
    "\n",
    "# TOTAL: 0.5828983925797634\n",
    "\n",
    "# AND \n",
    "\n",
    "# for (0, 11) score is 0.8016213740678662\n",
    "# for (11, 179) score is 0.4136798279457808\n",
    "# for (179, 186) score is 0.7025289942805701\n",
    "\n",
    "# TOTAL: 0.5828775060599996\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outcome\n",
    "\n",
    "| Model                       |file name | Local Recall   |LB score |  Ep |Comment|\n",
    "|-----------------------------|----------|----------------|---------|-----|-----------|\n",
    "| mnist_main (186 Dense out), custom loss  | model-2020-01-09-05-43 |0.0614  |  | 6  |Seems there is a bug because keras recall doesn't equal recall per model|\n",
    "| mnist_main (186 Dense out), binary_crossenthropy loss | model-2020-01-09-06-03 |0.5828 | 0.5723 | 6 | Custom loss makes training much worse|\n",
    "| mnist_main (3x softmax out) |model-2020-01-12-19-19 | 0.5829 | N/A | 11 | Doesn't makes much sence to submit\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
