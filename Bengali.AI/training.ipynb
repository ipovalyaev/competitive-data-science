{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import PIL.Image as Image, PIL.ImageDraw as ImageDraw, PIL.ImageFont as ImageFont\n",
    "import sklearn.metrics\n",
    "import scipy.special\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import h5py\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_gen = np.random.RandomState(41)\n",
    "\n",
    "HEIGHT = 137\n",
    "WIDTH = 236\n",
    "\n",
    "VALIDATION_SPLIT = 98\n",
    "TEST_SPLIT = 99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plan\n",
    "\n",
    "# make train on whole dataset (generator or what?)\t1\n",
    "# local validation scheme - simple K-fold for start\t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://medium.com/@mrgarg.rajat/training-on-large-datasets-that-dont-fit-in-memory-in-keras-60a974785d71\n",
    "# https://stackoverflow.com/questions/38805375/keras-batch-training-for-multiple-large-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To deal with dataset we need to have train/val/test datasets in hdf5 files\n",
    "use cases:\n",
    "\n",
    "1. local/colab testing and architecture tuning - train on train, then validate on val and measure final score on test\n",
    "2. while training final model for submittion - mixup all 3 \n",
    "3. while ensembling - use val as train for ensemble and test to verify score\n",
    "\n",
    "\n",
    "4. would be nice to keep class distibution across the datasets, but this can be done later\n",
    "\n",
    "hdf format is 2 datasets, 1st with pictures, 2nd with labels (same shape across 1 axis)\n",
    "split size for train could be the same as original files, excluding test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_files = [str.format('Data/bengaliai-cv19/train_image_data_{0}.parquet',i) for i in range(4) ]\n",
    "\n",
    "\n",
    "# train_df = pd.read_csv('Data/bengaliai-cv19/train.csv')\n",
    "# y_labels = train_df.image_id.copy()\n",
    "# y_1 = pd.get_dummies(train_df.vowel_diacritic).values\n",
    "# y_2 = pd.get_dummies(train_df.grapheme_root).values\n",
    "# y_3 = pd.get_dummies(train_df.consonant_diacritic).values\n",
    "# y = np.hstack([y_1,y_2,y_3])\n",
    "# assert(y.shape[1]==11+168+7)\n",
    "# del train_df, y_1,y_2,y_3\n",
    "# gc.collect()\n",
    "# assert (y_labels.shape[0]==y.shape[0])\n",
    "# n_samples = y.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "at this point we know the whole DS contains y.shape[0] = y_labels.shape[0] examples and we can split those accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffled_indexes = rand_gen.permutation(y.shape[0])\n",
    "# train_indexes = shuffled_indexes[:n_samples*VALIDATION_SPLIT//100]\n",
    "# valid_indexes = shuffled_indexes[n_samples*VALIDATION_SPLIT//100:n_samples*TEST_SPLIT//100]\n",
    "# test_indexes  = shuffled_indexes[n_samples*TEST_SPLIT//100:]\n",
    "\n",
    "# valid_images = []\n",
    "# valid_labels = []\n",
    "# test_images = []\n",
    "# test_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(4):\n",
    "#     chunk_train_indexes = np.compress((train_indexes>=i*50210) & (train_indexes<(i+1)*50210),train_indexes)\n",
    "#     chunk_valid_indexes = np.compress((valid_indexes>=i*50210) & (valid_indexes<(i+1)*50210),valid_indexes)\n",
    "#     chunk_test_indexes = np.compress((test_indexes>=i*50210) & (test_indexes<(i+1)*50210),test_indexes)\n",
    "\n",
    "#     print('loading '+train_files[i])\n",
    "#     images = pd.read_parquet(train_files[i])\n",
    "#     # we'd better use numpy indexing instead of combining numpy and pandas (not sure they are 100% consistent)\n",
    "#     # float 16 is enough to save from parquet to hdf5\n",
    "#     all_chunk_images = images.iloc[:,1:].values.astype(np.float16).reshape(-1, HEIGHT, WIDTH)/255.0\n",
    "#     del images\n",
    "#     gc.collect()\n",
    "\n",
    "#     # saving train, split by 2 files each\n",
    "    \n",
    "#     train_chunk_images = all_chunk_images[chunk_train_indexes-50210*i] # train\n",
    "#     train_y_chuck = y[chunk_train_indexes]\n",
    "#     assert(train_y_chuck.shape[0]==train_chunk_images.shape[0])\n",
    "    \n",
    "#     train_split_idx = train_y_chuck.shape[0]//2\n",
    "\n",
    "#     ## Not dry, but can live with it, as it's one time thing\n",
    "#     train_chunk_0_fname = str.format('Data/bengaliai-cv19/train_image_data_processed{0}.hdf5',2*i)\n",
    "#     h5f = h5py.File(train_chunk_0_fname, 'w')\n",
    "#     h5f.create_dataset('images', data = train_chunk_images[:train_split_idx])\n",
    "#     h5f.create_dataset('labels', data = train_y_chuck[:train_split_idx])\n",
    "#     h5f.close()\n",
    "#     print('saved '+train_chunk_0_fname)\n",
    "\n",
    "#     train_chunk_1_fname = str.format('Data/bengaliai-cv19/train_image_data_processed{0}.hdf5',2*i+1)\n",
    "#     h5f = h5py.File(train_chunk_1_fname, 'w')\n",
    "#     h5f.create_dataset('images', data = train_chunk_images[train_split_idx:])\n",
    "#     h5f.create_dataset('labels', data = train_y_chuck[train_split_idx:])\n",
    "#     h5f.close()\n",
    "#     print('saved '+train_chunk_1_fname)\n",
    "\n",
    "\n",
    "#     ## for reading - \n",
    "#     # In [10]: h5f = h5py.File('data.h5','r')\n",
    "#     # In [11]: b = h5f['dataset_1'][:]\n",
    "#     # In [12]: h5f.close()\n",
    "\n",
    "#     chunk_valid_images = all_chunk_images[chunk_valid_indexes-50210*i] # valid\n",
    "#     chunk_valid_labels = y[chunk_valid_indexes]\n",
    "#     assert(chunk_valid_labels.shape[0]==chunk_valid_images.shape[0])\n",
    "#     valid_images.append(chunk_valid_images)\n",
    "#     valid_labels.append(chunk_valid_labels)\n",
    "\n",
    "#     chunk_test_images = all_chunk_images[chunk_test_indexes-50210*i] # test\n",
    "#     chunk_test_labels = y[chunk_test_indexes]\n",
    "#     assert(chunk_test_labels.shape[0]==chunk_test_images.shape[0])\n",
    "#     test_images.append(chunk_test_images)\n",
    "#     test_labels.append(chunk_test_labels)\n",
    "\n",
    "#     del train_chunk_images, train_y_chuck\n",
    "#     gc.collect()\n",
    "#     print('completed '+train_files[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving valid and test \n",
    "\n",
    "# valid_images_all = np.vstack(valid_images)\n",
    "# valid_labels_all = np.vstack(valid_labels)\n",
    "# test_images_all = np.vstack(test_images)\n",
    "# test_labels_all = np.vstack(test_labels)\n",
    "\n",
    "# ## Not dry, but can live with it, as it's one time thing\n",
    "# h5f = h5py.File('Data/bengaliai-cv19/valid_image_data_processed.hdf5', 'w')\n",
    "# h5f.create_dataset('images', data = valid_images_all)\n",
    "# h5f.create_dataset('labels', data = valid_labels_all)\n",
    "# h5f.close()\n",
    "\n",
    "# h5f = h5py.File('Data/bengaliai-cv19/test_image_data_processed.hdf5', 'w')\n",
    "# h5f.create_dataset('images', data = test_images_all)\n",
    "# h5f.create_dataset('labels', data = test_labels_all)\n",
    "# h5f.close()\n",
    "\n",
    "# del valid_images,valid_labels,test_images,test_labels\n",
    "# del valid_images_all,valid_labels_all,test_images_all,test_labels_all\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def images_generator(batch_size):\n",
    "    \n",
    "    files = [str.format('Data/bengaliai-cv19/train_image_data_processed{0}.hdf5',i) for i in range(8) ]\n",
    "    current_file_idx = 0\n",
    "    already_send = 0     \n",
    "    steps = 0\n",
    "    \n",
    "    while True:\n",
    "#     ## for reading - \n",
    "#     # In [10]: h5f = h5py.File('data.h5','r')\n",
    "#     # In [11]: b = h5f['dataset_1'][:]\n",
    "#     # In [12]: h5f.close()\n",
    "        h5f = h5py.File(files[current_file_idx],'r')\n",
    "        train_X = h5f['images'][:]\n",
    "        train_Y = h5f['labels'][:]        \n",
    "        h5f.close()        \n",
    "#         print(\"loaded \"+str(files[current_file_idx])+ \" with size \"+str(train_X.shape))        \n",
    "        \n",
    "        while (already_send<train_X.shape[0]):\n",
    "            if (already_send+batch_size<train_X.shape[0]):\n",
    "                train_batch_X = train_X[already_send:already_send+batch_size,:]\n",
    "                train_batch_Y = train_Y[already_send:already_send+batch_size,:]\n",
    "            else:\n",
    "                train_batch_X = train_X[already_send:,:]\n",
    "                train_batch_Y = train_Y[already_send:,:]\n",
    "            assert (train_batch_X.shape[0]==train_batch_Y.shape[0])                \n",
    "            steps+=1\n",
    "#             print(\"sending \"+str(already_send) + \" steps \" + str(steps))\n",
    "            \n",
    "            yield np.expand_dims(train_batch_X,axis=3), train_batch_Y\n",
    "            already_send+=batch_size\n",
    "\n",
    "#         print(\"file completed, swithing to next. Steps = \"+str(steps))\n",
    "        already_send=0\n",
    "        current_file_idx+=1\n",
    "        if (current_file_idx==8):\n",
    "            current_file_idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_file_name = 'Data/bengaliai-cv19/valid_image_data_processed.hdf5'\n",
    "h5f = h5py.File(valid_file_name,'r')\n",
    "valid_X = np.expand_dims(h5f['images'][:],axis=3)\n",
    "valid_Y = h5f['labels'][:]\n",
    "h5f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    '''\n",
    "    Constructs the ML model used to predict handwritten digits.\n",
    "    Taken from https://github.com/tensorflow/models/blob/master/official/vision/image_classification/mnist_main.py\n",
    "    '''\n",
    "    image = tf.keras.layers.Input(shape=(137, 236, 1))\n",
    "    y = tf.keras.layers.Conv2D(filters=32,\n",
    "                             kernel_size=5,\n",
    "                             padding='same',\n",
    "                             activation='relu')(image)\n",
    "\n",
    "    y = tf.keras.layers.MaxPooling2D(pool_size=(2, 2),\n",
    "                                   strides=(2, 2),\n",
    "                                   padding='same')(y)\n",
    "    \n",
    "    y = tf.keras.layers.Conv2D(filters=32,\n",
    "                             kernel_size=5,\n",
    "                             padding='same',\n",
    "                             activation='relu')(y)\n",
    "    \n",
    "    y = tf.keras.layers.MaxPooling2D(pool_size=(2, 2),\n",
    "                                   strides=(2, 2),\n",
    "                                   padding='same')(y)\n",
    "    y = tf.keras.layers.Flatten()(y)\n",
    "    y = tf.keras.layers.Dense(1024, activation='relu')(y)\n",
    "    y = tf.keras.layers.Dropout(0.4)(y)\n",
    "    \n",
    "    out_m = tf.keras.layers.Dense(186, activation='sigmoid')(y)\n",
    "    \n",
    "#     out_0 = tf.keras.layers.Dense(11, activation='softmax')(y)\n",
    "#     out_1 = tf.keras.layers.Dense(168, activation='softmax')(y)\n",
    "#     out_2 = tf.keras.layers.Dense(7, activation='softmax')(y)\n",
    "    \n",
    "#     out_m=tf.concat(values=[out_0,out_1,out_2],axis=1)\n",
    "        \n",
    "#         # vowel_diacritic\n",
    "#         self.fc1 = nn.Linear(512,11)\n",
    "#         # grapheme_root\n",
    "#         self.fc2 = nn.Linear(512,168)\n",
    "#         # consonant_diacritic\n",
    "#         self.fc3 = nn.Linear(512,7)\n",
    "\n",
    "#     probs = tf.keras.layers.Dense(10, activation='softmax')(y)\n",
    "\n",
    "#      Idea of multiclass classification from the link below - replace activation with sigmoid\n",
    "#    loss=\"binary_crossentropy\", metrics=[\"accuracy\"]\n",
    "#     https://www.pyimagesearch.com/2018/05/07/multi-label-classification-with-keras/\n",
    "\n",
    "    model = tf.keras.models.Model(image, out_m, name='bengali')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = model.fit(\n",
    "#       np.expand_dims(X_train,axis=3),y_train,\n",
    "#       epochs=3,\n",
    "#       batch_size=64,\n",
    "#       validation_data=(np.expand_dims(X_test,axis=3),y_test)\n",
    "# #       steps_per_epoch=train_steps,\n",
    "# #       callbacks=callbacks,\n",
    "# #       validation_steps=num_eval_steps,\n",
    "# #       validation_data=eval_input_dataset,\n",
    "# #       validation_freq=flags_obj.epochs_between_evals\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def customLoss(yTrue,yPred):\n",
    "#     return keras.losses.categorical_crossentropy(yTrue[:,0:11],yPred[:,0:11])+\\\n",
    "#         2*keras.losses.categorical_crossentropy(yTrue[:,11:179],yPred[:,11:179])+\\\n",
    "#         keras.losses.categorical_crossentropy(yTrue[:,179:186],yPred[:,179:186])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # https://stackoverflow.com/questions/43076609/how-to-calculate-precision-and-recall-in-keras \n",
    "# # -> https://github.com/keras-team/keras/commit/a56b1a55182acf061b1eb2e2c86b48193a0e88f7\n",
    "\n",
    "# def recall(y_true, y_pred):\n",
    "#     \"\"\"Recall metric.\n",
    "#     Only computes a batch-wise average of recall.\n",
    "#     Computes the recall, a metric for multi-label classification of\n",
    "#     how many relevant items are selected.\n",
    "#     \"\"\"\n",
    "#     true_positives = keras.backend.sum(keras.backend.round(keras.backend.clip(y_true * y_pred, 0, 1)))\n",
    "#     possible_positives = keras.backend.sum(keras.backend.round(keras.backend.clip(y_true, 0, 1)))\n",
    "#     recall = true_positives / (possible_positives + keras.backend.epsilon())\n",
    "#     return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def customMetric(yTrue,yPred):\n",
    "# #     return keras.metrics.Recall(yTrue,yPred)\n",
    "#     return keras.metrics.Recall(yTrue[:,0:11],yPred[:,0:11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# customMetric(valid_Y,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "#     loss=customLoss,\n",
    "    loss = keras.losses.binary_crossentropy,\n",
    "    metrics=['binary_accuracy',keras.metrics.Recall()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "3078/3080 [============================>.] - ETA: 0s - loss: 0.0438 - binary_accuracy: 0.9880 - recall: 0.3984Epoch 1/6\n",
      "3080/3080 [==============================] - 139s 45ms/step - loss: 0.0438 - binary_accuracy: 0.9880 - recall: 0.3984 - val_loss: 0.0327 - val_binary_accuracy: 0.9903 - val_recall: 0.4915\n",
      "Epoch 2/6\n",
      "3078/3080 [============================>.] - ETA: 0s - loss: 0.0320 - binary_accuracy: 0.9904 - recall: 0.5293Epoch 1/6\n",
      "3080/3080 [==============================] - 130s 42ms/step - loss: 0.0320 - binary_accuracy: 0.9904 - recall: 0.5294 - val_loss: 0.0271 - val_binary_accuracy: 0.9916 - val_recall: 0.5481\n",
      "Epoch 3/6\n",
      "3078/3080 [============================>.] - ETA: 0s - loss: 0.0279 - binary_accuracy: 0.9913 - recall: 0.5798Epoch 1/6\n",
      "3080/3080 [==============================] - 130s 42ms/step - loss: 0.0279 - binary_accuracy: 0.9913 - recall: 0.5798 - val_loss: 0.0253 - val_binary_accuracy: 0.9921 - val_recall: 0.5774\n",
      "Epoch 4/6\n",
      "3078/3080 [============================>.] - ETA: 0s - loss: 0.0253 - binary_accuracy: 0.9919 - recall: 0.6155Epoch 1/6\n",
      "3080/3080 [==============================] - 130s 42ms/step - loss: 0.0253 - binary_accuracy: 0.9919 - recall: 0.6155 - val_loss: 0.0243 - val_binary_accuracy: 0.9922 - val_recall: 0.5885\n",
      "Epoch 5/6\n",
      "3078/3080 [============================>.] - ETA: 0s - loss: 0.0232 - binary_accuracy: 0.9924 - recall: 0.6454Epoch 1/6\n",
      "3080/3080 [==============================] - 129s 42ms/step - loss: 0.0232 - binary_accuracy: 0.9924 - recall: 0.6454 - val_loss: 0.0247 - val_binary_accuracy: 0.9925 - val_recall: 0.5996\n",
      "Epoch 6/6\n",
      "3078/3080 [============================>.] - ETA: 0s - loss: 0.0213 - binary_accuracy: 0.9928 - recall: 0.6719Epoch 1/6\n",
      "3080/3080 [==============================] - 129s 42ms/step - loss: 0.0213 - binary_accuracy: 0.9928 - recall: 0.6719 - val_loss: 0.0240 - val_binary_accuracy: 0.9926 - val_recall: 0.6140\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "      images_generator(batch_size=64),\n",
    "      epochs=6,\n",
    "      steps_per_epoch=3080,\n",
    "      validation_data = (valid_X, valid_Y)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "# plt.plot(history.history['recall'])\n",
    "# plt.plot(history.history['val_recall'])\n",
    "\n",
    "\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fname = 'models/model-' + datetime.datetime.now().strftime('%Y-%m-%d-%H-%M')\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(model_fname+'.json', \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(model_fname+'.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_fname = 'models/model-2020-01-04-11-33'\n",
    " model_fname = 'models/model-2020-01-09-06-03'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "binary_accuracy: 99.26%\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras.models\n",
    "# load json and create model\n",
    "json_file = open(model_fname+'.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = keras.models.model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(model_fname+'.hdf5')\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "# evaluate loaded model on test data\n",
    "loaded_model.compile(optimizer=keras.optimizers.Adam(),\n",
    "#     loss=customLoss,\n",
    "    loss = keras.losses.binary_crossentropy,\n",
    "    metrics=['binary_accuracy',keras.metrics.Recall()])\n",
    "score = loaded_model.evaluate(valid_X, valid_Y, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'binary_accuracy', 'recall_1']\n",
      "[0.024003607736700086, 0.99263954, 0.61387783]\n"
     ]
    }
   ],
   "source": [
    "print(loaded_model.metrics_names)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric from rules\n",
    "```\n",
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "\n",
    "scores = []\n",
    "for component in ['grapheme_root', 'consonant_diacritic', 'vowel_diacritic']:\n",
    "    y_true_subset = solution[solution[component] == component]['target'].values\n",
    "    y_pred_subset = submission[submission[component] == component]['target'].values\n",
    "    scores.append(sklearn.metrics.recall_score(\n",
    "        y_true_subset, y_pred_subset, average='macro'))\n",
    "final_score = np.average(scores, weights=[2,1,1])\n",
    "```\n",
    "also keep in mind target is constructed as\n",
    "```\n",
    "y_1 = pd.get_dummies(train_df.vowel_diacritic).values\n",
    "y_2 = pd.get_dummies(train_df.grapheme_root).values\n",
    "y_3 = pd.get_dummies(train_df.consonant_diacritic).values\n",
    "assert(y.shape[1]==11+168+7)\n",
    "del train_df, y_1,y_2,y_3\n",
    "```\n",
    "\n",
    "plan: \n",
    "1. get prediction on validation set\n",
    "2. try to compute metric for val set \n",
    "3. try to incorporate metric into training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=loaded_model.predict(valid_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(valid_Y.shape==predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for (0, 11) score is 0.8016213740678662\n",
      "for (11, 179) score is 0.4136798279457808\n",
      "for (179, 186) score is 0.7025289942805701\n",
      "\n",
      "TOTAL: 0.5828775060599996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning:\n",
      "\n",
      "Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "for intervals in [(0,11),(11,179),(179,186)]:    \n",
    "    y_true_subset = valid_Y[:,intervals[0]:intervals[1]]\n",
    "    y_pred_subset = predictions[:,intervals[0]:intervals[1]]\n",
    "    #\"hard\" max\n",
    "    y_pred_choice = np.zeros(y_pred_subset.shape, dtype='uint8')\n",
    "    y_pred_choice[np.arange(len(y_pred_subset)), y_pred_subset.argmax(axis=1)] = 1   \n",
    "    \n",
    "    partical_score = sklearn.metrics.recall_score(\n",
    "        y_true_subset, y_pred_choice, average='macro')\n",
    "    scores.append(partical_score)\n",
    "    \n",
    "    print('for '+str(intervals)+ ' score is '+str(partical_score))\n",
    "    \n",
    "\n",
    "final_score = np.average(scores, weights=[1,2,1])\n",
    "print()\n",
    "print('TOTAL: '+str(final_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outcome\n",
    "\n",
    "| Model                       | Total Recall   | Ep |Comment|\n",
    "|-----------------------------|----------------|----|-------------|\n",
    "| mnist_main (186 Dense out), custom loss  |0.0614          | 6  |Seems there is a bug because keras recall doesn't equal recall per model|\n",
    "| mnist_main (186 Dense out), binary_crossenthropy loss |0.5828 | 6 | Custom loss makes training much worse|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.all(np.sum(y_true_subset==1,axis=1)==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_subset[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out[0,:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
