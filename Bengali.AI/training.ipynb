{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.callbacks as cb \n",
    "import h5py\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image as Image, PIL.ImageDraw as ImageDraw, PIL.ImageFont as ImageFont\n",
    "import sklearn.metrics\n",
    "import scipy.special"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_gen = np.random.RandomState(41)\n",
    "\n",
    "HEIGHT = 137\n",
    "WIDTH = 236\n",
    "\n",
    "VALIDATION_SPLIT = 98\n",
    "TEST_SPLIT = 99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To deal with dataset we need to have train/val/test datasets in hdf5 files\n",
    "use cases:\n",
    "\n",
    "1. local/colab testing and architecture tuning - train on train, then validate on val and measure final score on test\n",
    "2. while training final model for submittion - mixup all 3 \n",
    "3. while ensembling - use val as train for ensemble and test to verify score\n",
    "\n",
    "\n",
    "4. would be nice to keep class distibution across the datasets, but this can be done later\n",
    "\n",
    "hdf format is 2 datasets, 1st with pictures, 2nd with labels (same shape across 1 axis)\n",
    "split size for train could be the same as original files, excluding test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_files = [str.format('Data/bengaliai-cv19/train_image_data_{0}.parquet',i) for i in range(4) ]\n",
    "\n",
    "\n",
    "# train_df = pd.read_csv('Data/bengaliai-cv19/train.csv')\n",
    "# y_labels = train_df.image_id.copy()\n",
    "# y_1 = pd.get_dummies(train_df.vowel_diacritic).values\n",
    "# y_2 = pd.get_dummies(train_df.grapheme_root).values\n",
    "# y_3 = pd.get_dummies(train_df.consonant_diacritic).values\n",
    "# y = np.hstack([y_1,y_2,y_3])\n",
    "# assert(y.shape[1]==11+168+7)\n",
    "# del train_df, y_1,y_2,y_3\n",
    "# gc.collect()\n",
    "# assert (y_labels.shape[0]==y.shape[0])\n",
    "# n_samples = y.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "at this point we know the whole DS contains y.shape[0] = y_labels.shape[0] examples and we can split those accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffled_indexes = rand_gen.permutation(y.shape[0])\n",
    "# train_indexes = shuffled_indexes[:n_samples*VALIDATION_SPLIT//100]\n",
    "# valid_indexes = shuffled_indexes[n_samples*VALIDATION_SPLIT//100:n_samples*TEST_SPLIT//100]\n",
    "# test_indexes  = shuffled_indexes[n_samples*TEST_SPLIT//100:]\n",
    "\n",
    "# valid_images = []\n",
    "# valid_labels = []\n",
    "# test_images = []\n",
    "# test_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(4):\n",
    "#     chunk_train_indexes = np.compress((train_indexes>=i*50210) & (train_indexes<(i+1)*50210),train_indexes)\n",
    "#     chunk_valid_indexes = np.compress((valid_indexes>=i*50210) & (valid_indexes<(i+1)*50210),valid_indexes)\n",
    "#     chunk_test_indexes = np.compress((test_indexes>=i*50210) & (test_indexes<(i+1)*50210),test_indexes)\n",
    "\n",
    "#     print('loading '+train_files[i])\n",
    "#     images = pd.read_parquet(train_files[i])\n",
    "#     # we'd better use numpy indexing instead of combining numpy and pandas (not sure they are 100% consistent)\n",
    "#     # float 16 is enough to save from parquet to hdf5\n",
    "#     all_chunk_images = images.iloc[:,1:].values.astype(np.float16).reshape(-1, HEIGHT, WIDTH)/255.0\n",
    "#     del images\n",
    "#     gc.collect()\n",
    "\n",
    "#     # saving train, split by 2 files each\n",
    "    \n",
    "#     train_chunk_images = all_chunk_images[chunk_train_indexes-50210*i] # train\n",
    "#     train_y_chuck = y[chunk_train_indexes]\n",
    "#     assert(train_y_chuck.shape[0]==train_chunk_images.shape[0])\n",
    "    \n",
    "#     train_split_idx = train_y_chuck.shape[0]//2\n",
    "\n",
    "#     ## Not dry, but can live with it, as it's one time thing\n",
    "#     train_chunk_0_fname = str.format('Data/bengaliai-cv19/train_image_data_processed{0}.hdf5',2*i)\n",
    "#     h5f = h5py.File(train_chunk_0_fname, 'w')\n",
    "#     h5f.create_dataset('images', data = train_chunk_images[:train_split_idx])\n",
    "#     h5f.create_dataset('labels', data = train_y_chuck[:train_split_idx])\n",
    "#     h5f.close()\n",
    "#     print('saved '+train_chunk_0_fname)\n",
    "\n",
    "#     train_chunk_1_fname = str.format('Data/bengaliai-cv19/train_image_data_processed{0}.hdf5',2*i+1)\n",
    "#     h5f = h5py.File(train_chunk_1_fname, 'w')\n",
    "#     h5f.create_dataset('images', data = train_chunk_images[train_split_idx:])\n",
    "#     h5f.create_dataset('labels', data = train_y_chuck[train_split_idx:])\n",
    "#     h5f.close()\n",
    "#     print('saved '+train_chunk_1_fname)\n",
    "\n",
    "\n",
    "#     ## for reading - \n",
    "#     # In [10]: h5f = h5py.File('data.h5','r')\n",
    "#     # In [11]: b = h5f['dataset_1'][:]\n",
    "#     # In [12]: h5f.close()\n",
    "\n",
    "#     chunk_valid_images = all_chunk_images[chunk_valid_indexes-50210*i] # valid\n",
    "#     chunk_valid_labels = y[chunk_valid_indexes]\n",
    "#     assert(chunk_valid_labels.shape[0]==chunk_valid_images.shape[0])\n",
    "#     valid_images.append(chunk_valid_images)\n",
    "#     valid_labels.append(chunk_valid_labels)\n",
    "\n",
    "#     chunk_test_images = all_chunk_images[chunk_test_indexes-50210*i] # test\n",
    "#     chunk_test_labels = y[chunk_test_indexes]\n",
    "#     assert(chunk_test_labels.shape[0]==chunk_test_images.shape[0])\n",
    "#     test_images.append(chunk_test_images)\n",
    "#     test_labels.append(chunk_test_labels)\n",
    "\n",
    "#     del train_chunk_images, train_y_chuck\n",
    "#     gc.collect()\n",
    "#     print('completed '+train_files[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving valid and test \n",
    "\n",
    "# valid_images_all = np.vstack(valid_images)\n",
    "# valid_labels_all = np.vstack(valid_labels)\n",
    "# test_images_all = np.vstack(test_images)\n",
    "# test_labels_all = np.vstack(test_labels)\n",
    "\n",
    "# ## Not dry, but can live with it, as it's one time thing\n",
    "# h5f = h5py.File('Data/bengaliai-cv19/valid_image_data_processed.hdf5', 'w')\n",
    "# h5f.create_dataset('images', data = valid_images_all)\n",
    "# h5f.create_dataset('labels', data = valid_labels_all)\n",
    "# h5f.close()\n",
    "\n",
    "# h5f = h5py.File('Data/bengaliai-cv19/test_image_data_processed.hdf5', 'w')\n",
    "# h5f.create_dataset('images', data = test_images_all)\n",
    "# h5f.create_dataset('labels', data = test_labels_all)\n",
    "# h5f.close()\n",
    "\n",
    "# del valid_images,valid_labels,test_images,test_labels\n",
    "# del valid_images_all,valid_labels_all,test_images_all,test_labels_all\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def images_generator(batch_size, shuffle=True, scale_range = [0.8,0.9,1.0,1.1,1.2], rotate_range=[-10,0,10]):    \n",
    "    files = [str.format('Data/bengaliai-cv19/train_image_data_processed{0}.hdf5',i) for i in range(8) ]\n",
    "    current_file_idx = 0\n",
    "    already_send = 0     \n",
    "    steps = 0\n",
    "    center = ( HEIGHT / 2, WIDTH/ 2)\n",
    "    \n",
    "    while True:\n",
    "        h5f = h5py.File(files[current_file_idx],'r')\n",
    "        train_X = (h5f['images'][:]).astype('float32')\n",
    "        train_Y = h5f['labels'][:]\n",
    "        h5f.close()        \n",
    "        \n",
    "        while (already_send<train_X.shape[0]):\n",
    "            if (already_send+batch_size<train_X.shape[0]):\n",
    "                train_batch_X = train_X[already_send:already_send+batch_size,:]\n",
    "                train_batch_Y = train_Y[already_send:already_send+batch_size,:]\n",
    "            else:\n",
    "                train_batch_X = train_X[already_send:,:]\n",
    "                train_batch_Y = train_Y[already_send:,:]\n",
    "            assert (train_batch_X.shape[0]==train_batch_Y.shape[0])\n",
    "            \n",
    "            train_batch_X_aug = np.array(train_batch_X,dtype='float32')\n",
    "            \n",
    "            for b in range(train_batch_X.shape[0]):\n",
    "                scale = np.random.choice(scale_range)\n",
    "                angle = np.random.choice(rotate_range)\n",
    "                M=cv2.getRotationMatrix2D(center, angle, scale)                \n",
    "                train_batch_X_aug[b]=cv2.warpAffine(train_batch_X[b], M, (WIDTH,HEIGHT),  borderValue=1.0)            \n",
    "            \n",
    "            assert (train_batch_X_aug.shape[0]==train_batch_Y.shape[0])\n",
    "            steps+=1            \n",
    "            yield np.expand_dims(train_batch_X_aug,axis=3), train_batch_Y\n",
    "            already_send+=batch_size\n",
    "        already_send=0\n",
    "        current_file_idx+=1\n",
    "        if (current_file_idx==8):\n",
    "            current_file_idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test generator\n",
    "# cnt = 0\n",
    "# batch_size = 5\n",
    "# f, ax = plt.subplots(5, 5, figsize=(16, 8))\n",
    "# ax = ax.flatten()\n",
    "\n",
    "# for i in images_generator(1):\n",
    "#     ax[cnt].imshow(np.squeeze((i[0][0]*255).astype(int)) , cmap='Greys')\n",
    "#     cnt+=1\n",
    "#     if cnt>=25:\n",
    "#         break;\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_file_name = 'Data/bengaliai-cv19/valid_image_data_processed.hdf5'\n",
    "h5f = h5py.File(valid_file_name,'r')\n",
    "valid_X = np.expand_dims(h5f['images'][:],axis=3)\n",
    "valid_Y = h5f['labels'][:]\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    '''\n",
    "    Constructs the ML model used to predict handwritten digits.\n",
    "    Taken from https://github.com/tensorflow/models/blob/master/official/vision/image_classification/mnist_main.py\n",
    "    '''\n",
    "    image = tf.keras.layers.Input(shape=(137, 236, 1))\n",
    "    y = tf.keras.layers.Conv2D(filters=32,\n",
    "                             kernel_size=5,\n",
    "                             padding='same',\n",
    "                             activation='relu')(image)\n",
    "\n",
    "    y = tf.keras.layers.MaxPooling2D(pool_size=(2, 2),\n",
    "                                   strides=(2, 2),\n",
    "                                   padding='same')(y)\n",
    "    \n",
    "    y = tf.keras.layers.Conv2D(filters=32,\n",
    "                             kernel_size=5,\n",
    "                             padding='same',\n",
    "                             activation='relu')(y)\n",
    "    \n",
    "    y = tf.keras.layers.MaxPooling2D(pool_size=(2, 2),\n",
    "                                   strides=(2, 2),\n",
    "                                   padding='same')(y)\n",
    "    y = tf.keras.layers.Flatten()(y)\n",
    "    y = tf.keras.layers.Dense(1024, activation='relu')(y)\n",
    "    y = tf.keras.layers.Dropout(0.4)(y)\n",
    "    \n",
    "    out_0 = tf.keras.layers.Dense(11, activation='softmax')(y)\n",
    "    out_1 = tf.keras.layers.Dense(168, activation='softmax')(y)\n",
    "    out_2 = tf.keras.layers.Dense(7, activation='softmax')(y)\n",
    "    \n",
    "    out_m=tf.concat(values=[out_0,out_1,out_2],axis=1)\n",
    "        \n",
    "    model = tf.keras.models.Model(image, out_m, name='bengali')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "def build_inception_model():\n",
    "    \n",
    "    img_input = keras.layers.Input(shape=(HEIGHT,WIDTH,1))\n",
    "    inception_model_def = InceptionV3(include_top=False, input_tensor=img_input,weights=None)\n",
    "    #Adding custom Layers \n",
    "    y = inception_model_def.output\n",
    "    y = tf.keras.layers.GlobalAveragePooling2D(name='avg_pool')(y)\n",
    "    y = tf.keras.layers.Dense(1024, activation='softmax', name='predictions')(y)\n",
    "    y = tf.keras.layers.Dropout(0.4)(y)\n",
    "    \n",
    "    out_0 = tf.keras.layers.Dense(11, activation='softmax')(y)\n",
    "    out_1 = tf.keras.layers.Dense(168, activation='softmax')(y)\n",
    "    out_2 = tf.keras.layers.Dense(7, activation='softmax')(y)\n",
    "    \n",
    "    out_m=tf.concat(values=[out_0,out_1,out_2],axis=1)\n",
    "\n",
    "    inception_model = tf.keras.models.Model(img_input, out_m, name='inception_bengali')\n",
    "    \n",
    "    return inception_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inception_model = build_inception_model()\n",
    "# # compile the model \n",
    "# inception_model.compile(\n",
    "#                     optimizer = keras.optimizers.Adam(),\n",
    "# #     optimizer = tf.keras.optimizers.SGD(lr=0.0001, momentum=0.9),\n",
    "#                     loss = tf.keras.losses.binary_crossentropy,\n",
    "#                     metrics=['binary_accuracy',tf.keras.metrics.Recall(name='recall')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Callbacks reused from \n",
    "# # https://www.kaggle.com/deshwalmahesh/bengali-ai-complete-beginner-tutorial-95-acc\n",
    "\n",
    "# model_fname_inception = 'models/inception_model-' + datetime.datetime.now().strftime('%Y-%m-%d-%H-%M')\n",
    "# # then go to callback definitions and run \n",
    "\n",
    "# R_LR_P = cb.ReduceLROnPlateau(monitor='val_recall',patience=3,verbose=1,factor=0.5,min_lr=0.00001,mode='max')\n",
    "# # if validation loss of out_1 is not decreasing for 3 consecutive epochs, decrease the learning rate by 0.5 \n",
    "# # given if learning rate is above 0.00001 and give us little insight on what has happened verbose=1\n",
    "\n",
    "# ES = cb.EarlyStopping(monitor='val_recall',patience=4, min_delta=0.0025,mode='max')\n",
    "# # stop the model from fitting data if validation loss has not decreased by 0.0025 in the last 5 epochs\n",
    "\n",
    "# MCP = cb.ModelCheckpoint(model_fname_inception+'.hdf5', monitor ='val_recall', verbose =1, \n",
    "#                       save_best_only = True, save_weights_only=True,mode='max')\n",
    "# # save the weights in a file name specified only if the validation loss of out_1 layer has improved from \n",
    "# # last save. out_1 because it's recall matters twice \n",
    "\n",
    "# callbacks = [R_LR_P,ES,MCP]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = inception_model.fit(\n",
    "#       images_generator(batch_size=64),\n",
    "#       epochs=30,\n",
    "#       steps_per_epoch=3080,\n",
    "#       validation_data = (valid_X, valid_Y),\n",
    "#       callbacks=callbacks\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.applications.vgg16 import VGG16\n",
    "\n",
    "def build_vgg16_model():    \n",
    "    img_input = keras.layers.Input(shape=(HEIGHT,WIDTH,1))\n",
    "    \n",
    "#     vgg16_model_def = VGG16(include_top=False, input_tensor=img_input,weights=None)\n",
    "    #Adding custom Layers \n",
    "#     y = vgg16_model_def.output\n",
    "    # Block 1\n",
    "    x = keras.layers.Conv2D(64, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block1_conv1')(img_input)\n",
    "    x = keras.layers.Conv2D(64, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block1_conv2')(x)\n",
    "    x = keras.layers.MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
    "\n",
    "    # Block 2\n",
    "    x = keras.layers.Conv2D(128, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block2_conv1')(x)\n",
    "    x = keras.layers.Conv2D(128, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block2_conv2')(x)\n",
    "    x = keras.layers.MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
    "\n",
    "    # Block 3\n",
    "    x = keras.layers.Conv2D(256, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block3_conv1')(x)\n",
    "    x = keras.layers.Conv2D(256, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block3_conv2')(x)\n",
    "    x = keras.layers.Conv2D(256, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block3_conv3')(x)\n",
    "    x = keras.layers.MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
    "\n",
    "    # Block 4\n",
    "    x = keras.layers.Conv2D(512, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block4_conv1')(x)\n",
    "    x = keras.layers.Conv2D(512, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block4_conv2')(x)\n",
    "    x = keras.layers.Conv2D(512, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block4_conv3')(x)\n",
    "    x = keras.layers.MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
    "\n",
    "    # Block 5\n",
    "    x = keras.layers.Conv2D(512, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block5_conv1')(x)\n",
    "    x = keras.layers.Conv2D(512, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block5_conv2')(x)\n",
    "    x = keras.layers.Conv2D(512, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block5_conv3')(x)\n",
    "    x = keras.layers.MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n",
    "    \n",
    "    # x->y\n",
    "    y = tf.keras.layers.GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "    \n",
    "    y = tf.keras.layers.Dense(4096, activation='softmax', name='predictions')(y)\n",
    "#     y = tf.keras.layers.Dropout(0.4)(y)\n",
    "    \n",
    "    out_0 = tf.keras.layers.Dense(11, activation='softmax')(y)\n",
    "    out_1 = tf.keras.layers.Dense(168, activation='softmax')(y)\n",
    "    out_2 = tf.keras.layers.Dense(7, activation='softmax')(y)\n",
    "    \n",
    "    out_m=tf.concat(values=[out_0,out_1,out_2],axis=1)\n",
    "\n",
    "    vgg16_model = tf.keras.models.Model(img_input, out_m, name='vgg16_bengali')\n",
    "    \n",
    "    return vgg16_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "vgg16_model = build_vgg16_model()\n",
    "# compile the model \n",
    "vgg16_model.compile(\n",
    "                    optimizer = keras.optimizers.Adam(),\n",
    "#     optimizer = tf.keras.optimizers.SGD(lr=0.0001, momentum=0.9),\n",
    "#                     loss = tf.keras.losses.binary_crossentropy,\n",
    "                    loss = tf.keras.losses.categorical_crossentropy,\n",
    "                    metrics=['binary_accuracy',tf.keras.metrics.Recall(name='recall')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "3079/3080 [============================>.] - ETA: 0s - loss: 11.4798 - binary_accuracy: 0.9849 - recall: 0.1623Epoch 1/30\n",
      "2008/3080 [==================>...........] - ETA: 2s - loss: 11.3010 - binary_accuracy: 0.9851 - recall: 0.2062\n",
      "Epoch 00001: val_recall improved from -inf to 0.20618, saving model to models/vgg16_model-2020-01-25-15-20.hdf5\n",
      "3080/3080 [==============================] - 1013s 329ms/step - loss: 11.4796 - binary_accuracy: 0.9849 - recall: 0.1623 - val_loss: 11.3010 - val_binary_accuracy: 0.9851 - val_recall: 0.2062\n",
      "Epoch 2/30\n",
      "3079/3080 [============================>.] - ETA: 0s - loss: 11.3115 - binary_accuracy: 0.9852 - recall: 0.2079Epoch 1/30\n",
      "2000/3080 [==================>...........] - ETA: 1s - loss: 11.2967 - binary_accuracy: 0.9851 - recall: 0.2058\n",
      "Epoch 00002: val_recall did not improve from 0.20618\n",
      "3080/3080 [==============================] - 909s 295ms/step - loss: 11.3113 - binary_accuracy: 0.9852 - recall: 0.2079 - val_loss: 11.2968 - val_binary_accuracy: 0.9851 - val_recall: 0.2062\n",
      "Epoch 3/30\n",
      "3079/3080 [============================>.] - ETA: 0s - loss: 11.3106 - binary_accuracy: 0.9852 - recall: 0.2079Epoch 1/30\n",
      "2000/3080 [==================>...........] - ETA: 2s - loss: 11.2966 - binary_accuracy: 0.9851 - recall: 0.2058\n",
      "Epoch 00003: val_recall did not improve from 0.20618\n",
      "3080/3080 [==============================] - 908s 295ms/step - loss: 11.3104 - binary_accuracy: 0.9852 - recall: 0.2079 - val_loss: 11.2967 - val_binary_accuracy: 0.9851 - val_recall: 0.2062\n",
      "Epoch 4/30\n",
      "3079/3080 [============================>.] - ETA: 0s - loss: 11.3106 - binary_accuracy: 0.9852 - recall: 0.2079Epoch 1/30\n",
      "2000/3080 [==================>...........] - ETA: 1s - loss: 11.2966 - binary_accuracy: 0.9851 - recall: 0.2058\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00004: val_recall did not improve from 0.20618\n",
      "3080/3080 [==============================] - 908s 295ms/step - loss: 11.3104 - binary_accuracy: 0.9852 - recall: 0.2079 - val_loss: 11.2968 - val_binary_accuracy: 0.9851 - val_recall: 0.2062\n",
      "Epoch 5/30\n",
      "3079/3080 [============================>.] - ETA: 0s - loss: 11.3101 - binary_accuracy: 0.9852 - recall: 0.2079Epoch 1/30\n",
      "2000/3080 [==================>...........] - ETA: 1s - loss: 11.2964 - binary_accuracy: 0.9851 - recall: 0.2058\n",
      "Epoch 00005: val_recall did not improve from 0.20618\n",
      "3080/3080 [==============================] - 908s 295ms/step - loss: 11.3099 - binary_accuracy: 0.9852 - recall: 0.2079 - val_loss: 11.2965 - val_binary_accuracy: 0.9851 - val_recall: 0.2062\n"
     ]
    }
   ],
   "source": [
    "# Callbacks reused from \n",
    "# https://www.kaggle.com/deshwalmahesh/bengali-ai-complete-beginner-tutorial-95-acc\n",
    "\n",
    "model_fname_vgg16 = 'models/vgg16_model-' + datetime.datetime.now().strftime('%Y-%m-%d-%H-%M')\n",
    "# then go to callback definitions and run \n",
    "\n",
    "R_LR_P = cb.ReduceLROnPlateau(monitor='val_recall',patience=3,verbose=1,factor=0.5,min_lr=0.00001,mode='max')\n",
    "# if validation loss of out_1 is not decreasing for 3 consecutive epochs, decrease the learning rate by 0.5 \n",
    "# given if learning rate is above 0.00001 and give us little insight on what has happened verbose=1\n",
    "\n",
    "ES = cb.EarlyStopping(monitor='val_recall',patience=4, min_delta=0.0025,mode='max')\n",
    "# stop the model from fitting data if validation loss has not decreased by 0.0025 in the last 5 epochs\n",
    "\n",
    "MCP = cb.ModelCheckpoint(model_fname_vgg16+'.hdf5', monitor ='val_recall', verbose =1, \n",
    "                      save_best_only = True, save_weights_only=True,mode='max')\n",
    "# save the weights in a file name specified only if the validation loss of out_1 layer has improved from \n",
    "# last save. out_1 because it's recall matters twice \n",
    "\n",
    "callbacks = [R_LR_P,ES,MCP]\n",
    "\n",
    "history = vgg16_model.fit(\n",
    "      images_generator(batch_size=64),\n",
    "      epochs=30,\n",
    "      steps_per_epoch=3080,\n",
    "      validation_data = (valid_X, valid_Y),\n",
    "      callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = vgg16_model.to_json()\n",
    "with open(model_fname_vgg16+'.json', \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def customLoss(yTrue,yPred):\n",
    "#     return keras.losses.categorical_crossentropy(yTrue[:,0:11],yPred[:,0:11])+\\\n",
    "#         2*keras.losses.categorical_crossentropy(yTrue[:,11:179],yPred[:,11:179])+\\\n",
    "#         keras.losses.categorical_crossentropy(yTrue[:,179:186],yPred[:,179:186])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # https://stackoverflow.com/questions/43076609/how-to-calculate-precision-and-recall-in-keras \n",
    "# # -> https://github.com/keras-team/keras/commit/a56b1a55182acf061b1eb2e2c86b48193a0e88f7\n",
    "\n",
    "# def recall(y_true, y_pred):\n",
    "#     \"\"\"Recall metric.\n",
    "#     Only computes a batch-wise average of recall.\n",
    "#     Computes the recall, a metric for multi-label classification of\n",
    "#     how many relevant items are selected.\n",
    "#     \"\"\"\n",
    "#     true_positives = keras.backend.sum(keras.backend.round(keras.backend.clip(y_true * y_pred, 0, 1)))\n",
    "#     possible_positives = keras.backend.sum(keras.backend.round(keras.backend.clip(y_true, 0, 1)))\n",
    "#     recall = true_positives / (possible_positives + keras.backend.epsilon())\n",
    "#     return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def customMetric(yTrue,yPred):\n",
    "# #     return keras.metrics.Recall(yTrue,yPred)\n",
    "#     return keras.metrics.Recall(yTrue[:,0:11],yPred[:,0:11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# customMetric(valid_Y,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "#     loss=customLoss,\n",
    "    loss = keras.losses.binary_crossentropy,\n",
    "    metrics=['binary_accuracy',keras.metrics.Recall()])\n",
    "\n",
    "model_fname = 'models/model-' + datetime.datetime.now().strftime('%Y-%m-%d-%H-%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(model_fname+'.json', \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "      images_generator(batch_size=64),\n",
    "      epochs=12,\n",
    "      steps_per_epoch=3080,\n",
    "      validation_data = (valid_X, valid_Y),\n",
    "      callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "# plt.plot(history.history['recall'])\n",
    "# plt.plot(history.history['val_recall'])\n",
    "\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_fname = 'models/model-2020-01-04-11-33'\n",
    "# model_fname = 'models/model-2020-01-09-06-03'\n",
    "# model_fname = 'models/model-2020-01-12-19-19'\n",
    "model_fname = 'models/vgg16_model-2020-01-15-05-06'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate inference phase\n",
    "\n",
    "import tensorflow.keras.models\n",
    "# load json and create model\n",
    "json_file = open(model_fname+'.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = keras.models.model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(model_fname+'.hdf5')\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "# evaluate loaded model on test data\n",
    "loaded_model.compile(optimizer=keras.optimizers.Adam(),\n",
    "#     loss=customLoss,\n",
    "    loss = keras.losses.binary_crossentropy,\n",
    "    metrics=['binary_accuracy',keras.metrics.Recall()])\n",
    "score = loaded_model.evaluate(valid_X, valid_Y, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(loaded_model.metrics_names)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric from rules\n",
    "```\n",
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "\n",
    "scores = []\n",
    "for component in ['grapheme_root', 'consonant_diacritic', 'vowel_diacritic']:\n",
    "    y_true_subset = solution[solution[component] == component]['target'].values\n",
    "    y_pred_subset = submission[submission[component] == component]['target'].values\n",
    "    scores.append(sklearn.metrics.recall_score(\n",
    "        y_true_subset, y_pred_subset, average='macro'))\n",
    "final_score = np.average(scores, weights=[2,1,1])\n",
    "```\n",
    "also keep in mind target is constructed as\n",
    "```\n",
    "y_1 = pd.get_dummies(train_df.vowel_diacritic).values\n",
    "y_2 = pd.get_dummies(train_df.grapheme_root).values\n",
    "y_3 = pd.get_dummies(train_df.consonant_diacritic).values\n",
    "assert(y.shape[1]==11+168+7)\n",
    "del train_df, y_1,y_2,y_3\n",
    "```\n",
    "\n",
    "plan: \n",
    "1. get prediction on validation set\n",
    "2. try to compute metric for val set \n",
    "3. try to incorporate metric into training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=loaded_model.predict(valid_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(valid_Y.shape==predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "\n",
    "for intervals in [(0,11),(11,179),(179,186)]:    \n",
    "    y_true_subset = valid_Y[:,intervals[0]:intervals[1]]\n",
    "    y_pred_subset = predictions[:,intervals[0]:intervals[1]]\n",
    "    #\"hard\" max\n",
    "    y_pred_choice = np.zeros(y_pred_subset.shape, dtype='uint8')\n",
    "    y_pred_choice[np.arange(len(y_pred_subset)), y_pred_subset.argmax(axis=1)] = 1   \n",
    "    \n",
    "    partical_score = sklearn.metrics.recall_score(\n",
    "        y_true_subset, y_pred_choice, average='macro')\n",
    "    scores.append(partical_score)\n",
    "    \n",
    "    print('for '+str(intervals)+ ' score is '+str(partical_score))\n",
    "    \n",
    "\n",
    "final_score = np.average(scores, weights=[1,2,1])\n",
    "print()\n",
    "print('TOTAL: '+str(final_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for model-2020-01-12-19-19\n",
    "# for (0, 11) score is 0.8161456276283384\n",
    "# for (11, 179) score is 0.41152848969600087\n",
    "# for (179, 186) score is 0.6923909632987134\n",
    "\n",
    "# TOTAL: 0.5828983925797634\n",
    "\n",
    "# AND \n",
    "\n",
    "# for (0, 11) score is 0.8016213740678662\n",
    "# for (11, 179) score is 0.4136798279457808\n",
    "# for (179, 186) score is 0.7025289942805701\n",
    "\n",
    "# TOTAL: 0.5828775060599996\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outcome\n",
    "\n",
    "| Model                       |file name | Local Recall   |LB score |  Ep |Comment|\n",
    "|-----------------------------|----------|----------------|---------|-----|-----------|\n",
    "| mnist_main (186 Dense out), custom loss  | model-2020-01-09-05-43 |0.0614  |  | 6  |Seems there is a bug because keras recall doesn't equal recall per model|\n",
    "| mnist_main (186 Dense out), binary_crossenthropy loss | model-2020-01-09-06-03 |0.5828 | 0.5723 | 6 | Custom loss makes training much worse|\n",
    "| mnist_main (3x softmax out) |model-2020-01-12-19-19 | 0.5829 | N/A | 11 | Doesn't makes much sence to submit\n",
    "| vgg16 | vgg16_model-2020-01-15-05-06 | 0.0614 | N/A | 1 | Model is not training after 1 epoch (to add shuffles, augment)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
