{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\n# import PIL.Image as Image, PIL.ImageDraw as ImageDraw, PIL.ImageFont as ImageFont\n# import sklearn.metrics\n# import scipy.special\n\n# import plotly.graph_objects as go\n# import matplotlib.pyplot as plt\nimport gc\nimport tensorflow as tf\nfrom tensorflow import keras\nimport tensorflow.keras.models\nimport h5py\n# import datetime\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"HEIGHT = 137\nWIDTH = 236\n# From kaggle\nROOT_DIR = '/kaggle/input/'\n# local\n# ROOT_DIR = './Data/bengaliai-cv19/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_fname = ROOT_DIR+'models/model-2020-01-09-06-03'\n\njson_file = open(model_fname+'.json', 'r')\nloaded_model_json = json_file.read()\njson_file.close()\nloaded_model = keras.models.model_from_json(loaded_model_json)\n# load weights into new model\nloaded_model.load_weights(model_fname+'.hdf5')\nprint(\"Loaded model from disk\")\n\n# evaluate loaded model on test data\nloaded_model.compile(optimizer=keras.optimizers.Adam(),\n#     loss=customLoss,\n    loss = keras.losses.binary_crossentropy,\n    metrics=['binary_accuracy',keras.metrics.Recall()])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv(ROOT_DIR+'bengaliai-cv19/test.csv')\ntest_files = [str.format(ROOT_DIR+'bengaliai-cv19/test_image_data_{0}.parquet',i) for i in range(4) ]\nsubmission = pd.read_csv(ROOT_DIR+'bengaliai-cv19/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"offset = 0\nfor fname in test_files:\n    data = pd.read_parquet(fname)\n    \n    print('loading file')\n    chunk_images = np.expand_dims(\n        data.iloc[:,1:].values.astype(np.float16).reshape(-1, HEIGHT, WIDTH)/255.0,\n        axis=3)\n    \n    chunk_files_count = chunk_images.shape[0]\n    print(str(chunk_files_count)+' loaded')\n    \n    predictions_chunk = loaded_model.predict(chunk_images)\n    print ('predicted ' +  str(predictions_chunk.shape))\n\n    chunk_vowel_diacritic =  predictions_chunk[:,0:11].argmax(axis=1)\n    chunk_grapheme_root = predictions_chunk[:,11:179].argmax(axis=1)\n    chunk_consonant_diacritic = predictions_chunk[:,179:186].argmax(axis=1)\n    \n    idxes = [3*i+offset for i in range(chunk_files_count)]\n    submission.loc[:,'target'].iloc[idxes]=chunk_consonant_diacritic\n\n    idxes = [1+3*i+offset for i in range(chunk_files_count)]\n    submission.loc[:,'target'].iloc[idxes]=chunk_grapheme_root\n\n    idxes = [2+3*i+offset for i in range(chunk_files_count)]\n    submission.loc[:,'target'].iloc[idxes]=chunk_vowel_diacritic\n    \n    offset+=3*chunk_files_count\n    print ('transformed '+str(offset))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}