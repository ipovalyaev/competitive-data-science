{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from itertools import product\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import gc\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import preprocessing\n",
    "import xgboost\n",
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "%matplotlib inline \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = '../readonly/final_project_data/'\n",
    "\n",
    "transactions    = pd.read_csv(os.path.join(DATA_FOLDER, 'sales_train.csv.gz'))\n",
    "items           = pd.read_csv(os.path.join(DATA_FOLDER, 'items.csv'))\n",
    "item_categories = pd.read_csv(os.path.join(DATA_FOLDER, 'item_categories.csv'))\n",
    "shops           = pd.read_csv(os.path.join(DATA_FOLDER, 'shops.csv'))\n",
    "\n",
    "test_set=pd.read_csv(os.path.join(DATA_FOLDER, 'test.csv.gz'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset exploration \n",
    "based on Pandas basics notebook from week1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## From week 1:\n",
    "# How many items are there, such that their price stays constant during the whole period of time?\n",
    "# Remember, the data can sometimes be noisy. :)\n",
    "# grouping3=pd.DataFrame(transactions[['item_id','item_price']],copy=True)\n",
    "# grouping3['item_price']=abs(grouping3['item_price']).round(decimals=2)\n",
    "# grouping3=grouping3.drop_duplicates()\n",
    "# sum3=grouping3.groupby('item_id').count()\n",
    "# sum3[sum3['item_price']==1].count()\n",
    "\n",
    "# Maybe could be the feature (price changes count, last price delta, price changed time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA - to do :\n",
    " 1. analyze time dependancies if any for different intervals\n",
    " 2. plot some dependancies?\n",
    " 3. From the task: Target distribution is visualized, time trend is assessed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing simple submittion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>A good exercise is to reproduce previous_value_benchmark.</b>\n",
    "\n",
    "<i> Stolen from somewhere from course materials </i>\n",
    "\n",
    "\n",
    "As the name suggest - in this benchmark for the each shop/item pair our predictions are just monthly sales from the previous month, i.e. October 2015.\n",
    "\n",
    "The most important step at reproducing this score is correctly aggregating daily data and constructing monthly sales data frame. You need to get lagged values, fill NaNs with zeros and clip the values into [0,20] range. If you do it correctly, you'll get precisely 1.16777 on the public leaderboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_filter=transactions.set_index(pd.to_datetime(transactions[\"date\"],format='%d.%m.%Y'))[\"2015-10\"]\n",
    "# df_october=pd.DataFrame(df_filter)\n",
    "\n",
    "# df_october_groupped = df_october.groupby(['shop_id','item_id'],as_index=False).agg({'item_cnt_day':'sum'})\n",
    "\n",
    "# predictions = pd.merge(test_set,df_october_groupped,\n",
    "#                        left_on=('shop_id','item_id'), right_on=('shop_id','item_id'), how='left')\n",
    "# ##filling NAs\n",
    "# predictions.item_cnt_day=predictions.item_cnt_day.fillna(0.0)\n",
    "# ## clipping\n",
    "# predictions.loc[predictions.item_cnt_day>20,'item_cnt_day']=20\n",
    "# predictions.loc[predictions.item_cnt_day<0,'item_cnt_day']=0\n",
    "# ##dropping extra colums and indexes after merge\n",
    "# predictions.drop(labels=['shop_id','item_id'],axis=1,inplace=True)\n",
    "# predictions.rename(columns={'item_cnt_day':'item_cnt_month'},inplace=True)\n",
    "\n",
    "# # converting  ID back to int\n",
    "# predictions.ID = predictions.ID.astype(int)\n",
    "\n",
    "# filename = 'submition_{}.csv'.format(time.strftime('%Y_%m_%d_%H_%M',time.localtime()))\n",
    "# filename = os.path.join(DATA_FOLDER,filename)\n",
    "# predictions.to_csv(filename,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train test split investigation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: \n",
      " items: 5100 shops: 42\n",
      " total: 214200 supposed total: 214200\n",
      "Data set: \n",
      " items: 21807 shops: 60\n",
      " total: 1308420\n"
     ]
    }
   ],
   "source": [
    "items_test = test_set.item_id.nunique()\n",
    "shops_test = test_set.shop_id.nunique()\n",
    "\n",
    "items_train = transactions.item_id.unique().shape[0]\n",
    "shops_train = transactions.shop_id.unique().shape[0]\n",
    "\n",
    "print ('Test set: \\n'+\\\n",
    "       ' items: ' + str(items_test) + ' shops: ' + str(shops_test) + \\\n",
    "       '\\n total: '+ str(test_set[\"ID\"].count()) + ' supposed total: '+str(items_test*shops_test) + \\\n",
    "       '\\nData set: \\n'+\\\n",
    "       ' items: ' + str(items_train) + ' shops: ' + str(shops_train) + \\\n",
    "       '\\n total: ' + str (items_train*shops_train)\n",
    "      )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the cartesian product is used in a test set, however only some of shops and items included into test set.  This suggests potential dataleak, but further investigation needed.\n",
    "also hypotesis to test - shops are beeing closed, as well items are get offsale. Maybe data missing in testset is just one which are not exists anymore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "excluded_shops [ 0  1  8  9 11 13 17 20 23 27 29 30 32 33 40 43 51 54]\n",
      "items only in train count 17070\n",
      "items only in test count 363\n",
      "average date_block for: \n",
      "  exluded shops: 11.962617895419658\n",
      "  excluded items: 10.468482249471924\n",
      "  average for all data : 14.56991146343017\n",
      "last seen:\n",
      "  exluded shops: 20.38888888888889\n",
      "  excluded items: 18.841769185705918\n",
      "  average for all shops : 29.216666666666665\n",
      "  average for all items : 21.760489750997387\n"
     ]
    }
   ],
   "source": [
    "excluded_shops = np.setxor1d(transactions.shop_id.unique(),test_set.shop_id.unique())\n",
    "items_train_only = transactions[~transactions.item_id.isin(test_set.item_id)].item_id.unique()\n",
    "\n",
    "print ('excluded_shops ' + str(excluded_shops))\n",
    "print ('items only in train count ' + str(items_train_only.shape[0]))\n",
    "\n",
    "# There is also items only in test set, but let's ignore it for now\n",
    "print ('items only in test count ' + str(test_set[~test_set.item_id.isin(transactions.item_id.unique())].\\\n",
    "                                         item_id.unique().shape[0]))\n",
    "print ('average date_block for: \\n'+\\\n",
    "       '  exluded shops: ' + \\\n",
    "        str(transactions[transactions.shop_id.isin(excluded_shops)].date_block_num.mean()) + \\\n",
    "       '\\n  excluded items: ' + \\\n",
    "        str(transactions[transactions.item_id.isin(items_train_only)].date_block_num.mean()) + \\\n",
    "        '\\n  average for all data : ' + \\\n",
    "        str(transactions.date_block_num.mean()) + \\\n",
    "       '\\nlast seen:' + \\\n",
    "       '\\n  exluded shops: ' + \\\n",
    "       str(transactions[transactions.shop_id.isin(excluded_shops)]. \\\n",
    "           groupby('shop_id'). \\\n",
    "           agg({'date_block_num':'max'}).mean().values[0]) +\\\n",
    "       '\\n  excluded items: ' + \\\n",
    "       str(transactions[transactions.item_id.isin(items_train_only)]. \\\n",
    "           groupby('item_id'). \\\n",
    "           agg({'date_block_num':'max'}).mean().values[0]) +\\\n",
    "       '\\n  average for all shops : ' + \\\n",
    "       str(transactions.groupby('shop_id').agg({'date_block_num':'max'}).mean().values[0]) +\\\n",
    "       '\\n  average for all items : ' + \\\n",
    "       str(transactions.groupby('item_id').agg({'date_block_num':'max'}).mean().values[0]) \n",
    "      )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "seems average date is less for absent shops, so we can somehow conlude the shops not in test set are closed. \n",
    "However, it's not that clear for items, why only about 1/4 of items are in test set. \n",
    "\n",
    "It also doesn't looks like there are only items which was sold, as leaderboard probing shown mean 0.2839\n",
    "https://www.kaggle.com/c/competitive-data-science-predict-future-sales/discussion/79142\n",
    "\n",
    "There could be a case items excluded are the one's had 0 sales in all the possible shops within the given month (which also suggested by train/test split in week4). The last one can be tested by grouping transactions by date_block_num and count unique items over to see if it's close to test set size\n",
    "\n",
    "This can be utilized together with mean information above during predicting for items not in dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6879.764705882353"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions.groupby('date_block_num').agg({'item_id':'nunique'}).mean().values[0]\n",
    "\n",
    "## Seems pretty close (espesially if look and number's not mean - 5100 looks reasonable values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation\n",
    "\n",
    "Before playing with any kind of models validation has to be setup. \n",
    "Some ideas could be taken from week4. \n",
    "\n",
    "In contrast with it 4 cycles of validation to be used - train on date_block_num [0:i] -> validate on [i+1], where i [30,31,32,33]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assume every model should take dataset like transations and test pairs (like test_set) and return dataset of prediction \n",
    "[shop_id, item_id, prediction] for the month, next to the last present in dataset. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constant_model(train_set, test_set,fit_col):\n",
    "    # we can take global mean of training data, but it's not so easy to calculate, \n",
    "    # as we need to produce proper fraction of zeros. So just constant for some period taken\n",
    "    return np.ones((test_set.shape[0],1),dtype='float32')*0.298 ## true_values['item_cnt_day'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def previous_value_model(train_set, test_set,fit_col):\n",
    "    max_date_block = train_set.date_block_num.max()\n",
    "    \n",
    "    predictions = test_set.merge(train_set[train_set.date_block_num == max_date_block],\\\n",
    "        how='left',on=['shop_id','item_id']).fillna(0.0)\n",
    "    \n",
    "    predictions.loc[predictions.target>20,'target']=20\n",
    "    predictions.loc[predictions.target<0,'target']=0\n",
    "    \n",
    "    return predictions['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lin_model (train_set, test_set,fit_col):\n",
    "    lr = LinearRegression()\n",
    "    X = train_set[fit_col]\n",
    "    y = train_set['target']\n",
    "    lr.fit(X.values,y.values)\n",
    "    predictions = lr.predict(test_set[fit_col].values)\n",
    "\n",
    "    return predictions.clip(min=0.0, max =20.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lin_model_with_feature_norm (train_set, test_set,fit_col):\n",
    "    ## Seems with MinMaxScaler exactly the same metrics as lin_model. Just, probably given by the \n",
    "    ## fact feature are centered in LinearRegression and not too far from 0-1\n",
    "    ## \n",
    "\n",
    "    #     scaler = preprocessing.MinMaxScaler()\n",
    "    #     scaler = preprocessing.StandardScaler()\n",
    "    scaler = preprocessing.RobustScaler()\n",
    "\n",
    "    reduced_X_train = pd.DataFrame(train_set[fit_col+['target']],copy=True)\n",
    "    X_train_minmax = scaler.fit_transform(reduced_X_train[fit_col])\n",
    "    reduced_X_train[fit_col] = X_train_minmax\n",
    "\n",
    "    reduced_X_test = pd.DataFrame(test_set[fit_col],copy=True)\n",
    "    X_test_minmax = scaler.transform(reduced_X_test)\n",
    "    reduced_X_test[fit_col] = X_test_minmax\n",
    "\n",
    "    predictions=lin_model(reduced_X_train,reduced_X_test,fit_col)\n",
    "    \n",
    "    del reduced_X_train, reduced_X_test, X_train_minmax, X_test_minmax\n",
    "    gc.collect();\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgboost_model(train_set, test_set,fit_col):\n",
    "    xgb_model = xgboost.XGBRegressor(n_jobs=4,objective='reg:squarederror')\n",
    "    xgb_model.fit(train_set[fit_col].values,train_set['target'].values)\n",
    "    predictions = xgb_model.predict(test_set[fit_col].values)\n",
    "    \n",
    "    return predictions.clip(min=0.0, max =20.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lightgbm_model(train_set, test_set,fit_col):\n",
    "    lgb_params = {\n",
    "#                'feature_fraction': 0.75,\n",
    "               'metric': 'rmse',\n",
    "               'nthread':4, \n",
    "#                'min_data_in_leaf': 2**7, \n",
    "#                'bagging_fraction': 0.75, \n",
    "#                'learning_rate': 0.03, \n",
    "               'objective': 'mse', \n",
    "#                'bagging_seed': 2**7, \n",
    "#                'num_leaves': 2**7,\n",
    "#                'bagging_freq':1,\n",
    "#                'verbose':0 \n",
    "              }\n",
    "\n",
    "    model = lgb.train(lgb_params, lgb.Dataset(train_set[fit_col].values, label=train_set['target'].values), 100)\n",
    "    predictions = model.predict(test_set[fit_col].values)\n",
    "    return predictions.clip(min=0.0, max =20.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cartesian_product(*arrays):\n",
    "    la = len(arrays)\n",
    "    dtype = np.result_type(*arrays)\n",
    "    arr = np.empty([len(a) for a in arrays] + [la], dtype=dtype)\n",
    "    for i, a in enumerate(np.ix_(*arrays)):\n",
    "        arr[...,i] = a\n",
    "    return arr.reshape(-1, la)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_shifted_features(trainset, testset):\n",
    "    \n",
    "    '''\n",
    "    added features for sale in same shop, then for same item and then for pair (shop, item) for 1,2,3,4,6,9,12 month ago\n",
    "    in : trainset - pandas dataframe with train data (transactions), testset - shop_id, item_id pairs for predictions\n",
    "    out - tuple (trainset, testset), where trainset is groupped by shop_id, item_id either\n",
    "    \n",
    "    '''\n",
    "    index_cols = ['shop_id', 'item_id', 'date_block_num']\n",
    "    shift_range = [1, 2, 3, 4, 5, 12]\n",
    "    # shift_range = [1, 2]\n",
    "\n",
    "    grid = [] \n",
    "    for block_num in trainset['date_block_num'].unique():\n",
    "        cur_shops = trainset.loc[trainset['date_block_num'] == block_num, 'shop_id'].unique()\n",
    "        cur_items = trainset.loc[trainset['date_block_num'] == block_num, 'item_id'].unique()\n",
    "        # https://docs.python.org/3/library/itertools.html#itertools.product\n",
    "        # Cartesian product of input iterables.\n",
    "        grid.append(cartesian_product(cur_shops, cur_items, np.array([block_num])))\n",
    "    # Turn the grid into a dataframe\n",
    "    grid = pd.DataFrame(np.vstack(grid), columns = index_cols,dtype=np.int32)\n",
    "    gb = trainset.groupby(index_cols,as_index=False).agg({'item_cnt_day':'sum'})\n",
    "    gb.rename(columns={'item_cnt_day':'target'},inplace=True)\n",
    "    # Join it to the grid\n",
    "    all_data = pd.merge(grid, gb, how='left', on=['shop_id','item_id','date_block_num']).fillna(0)\n",
    "\n",
    "    # Same as above but with shop-month aggregates\n",
    "    gb = trainset.groupby(['shop_id', 'date_block_num'],as_index=False).agg({'item_cnt_day':'sum'})\n",
    "    gb.rename(columns={'item_cnt_day':'target_shop'},inplace=True)\n",
    "    all_data = pd.merge(all_data, gb, how='left', on=['shop_id', 'date_block_num']).fillna(0)\n",
    "\n",
    "    # Same as above but with item-month aggregates\n",
    "    gb = trainset.groupby(['item_id', 'date_block_num'],as_index=False).agg({'item_cnt_day':'sum'})\n",
    "    gb.rename(columns={'item_cnt_day':'target_item'},inplace=True)\n",
    "    all_data = pd.merge(all_data, gb, how='left', on=['item_id', 'date_block_num']).fillna(0)\n",
    "    \n",
    "    # List of columns that we will use to create lags\n",
    "    cols_to_rename = list(all_data.columns.difference(index_cols))\n",
    "    \n",
    "    max_block_num = all_data.date_block_num.max()\n",
    "    testset['date_block_num']=max_block_num+1\n",
    "    # shifted features are also done in kinda weird fashion - probably there is easier way \n",
    "    for month_shift in shift_range:\n",
    "        train_shift = all_data[index_cols + cols_to_rename].copy()\n",
    "        train_shift['date_block_num'] = train_shift['date_block_num'] + month_shift\n",
    "        foo = lambda x: '{}_lag_{}'.format(x, month_shift) if x in cols_to_rename else x\n",
    "        train_shift = train_shift.rename(columns=foo) #rename using lambda.Doesn't seems most transparent, but ok\n",
    "        train_shift.head()        \n",
    "        testset = pd.merge(testset, train_shift, on=index_cols, how='left').fillna(0)\n",
    "        all_data = pd.merge(all_data, train_shift, on=index_cols, how='left').fillna(0)\n",
    "        \n",
    "    del train_shift\n",
    "\n",
    "    # Don't use old data which have 0 shift and will just confuse the model\n",
    "    all_data = all_data[all_data['date_block_num'] >= 12]\n",
    "\n",
    "    # List of all lagged features\n",
    "    # this will cause a problem, if 1 is excluded and 10 included, for ex. But probably this shouldn't happen\n",
    "    fit_cols = [col for col in all_data.columns if col[-1] in [str(item) for item in shift_range]] \n",
    "    # We will drop these at fitting stage\n",
    "    to_drop_cols = list(set(list(all_data.columns)) - (set(fit_cols)|set(index_cols)) - set (['target'])) \n",
    "    all_data.drop(to_drop_cols,axis=1,inplace=True)\n",
    "    \n",
    "    \n",
    "    del grid, gb \n",
    "    gc.collect();\n",
    "    \n",
    "    return (all_data,testset,fit_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_block = 30\n",
    "to_block = 33\n",
    "\n",
    "def validate (models):\n",
    "    outcome = []\n",
    "    for i in range(from_block,to_block+1):    \n",
    "        print ('validation: generating test and train for i='+str(i))\n",
    "        train_transactions = transactions[transactions.date_block_num<i]\n",
    "        test_transactions = transactions[transactions.date_block_num==i]\n",
    "\n",
    "        test_set = pd.DataFrame(cartesian_product(test_transactions.shop_id.unique(), \n",
    "                                       test_transactions.item_id.unique()),columns=['shop_id','item_id'])\n",
    "\n",
    "        true_values = test_set.merge ( \\\n",
    "            test_transactions.groupby(['shop_id','item_id'],as_index=False).agg({'item_cnt_day':'sum'}), \\\n",
    "            how = 'left' ).fillna(0)\n",
    "        \n",
    "\n",
    "\n",
    "        (train_groupped_with_shifted, test_set_with_shifted, fit_col) = \\\n",
    "            generate_shifted_features(train_transactions,true_values[['shop_id','item_id']])\n",
    "\n",
    "        for model in models:\n",
    "            print ('validation: testing model ' + model.__name__)\n",
    "            predictions = model(train_groupped_with_shifted, test_set_with_shifted,fit_col)\n",
    "            \n",
    "            # According to competition description validation is done with clipping, so we should do the same\n",
    "            # Model is responsible for it's own clipping if nessesary\n",
    "            # r2 should be as close to 1 as possible. 0 is constant model            \n",
    "            r2s = r2_score(true_values['item_cnt_day'].clip(lower=0.0, upper =20.0), predictions)\n",
    "            rmse = np.sqrt(mean_squared_error(true_values['item_cnt_day'].clip(lower=0.0, upper =20.0), predictions))\n",
    "            \n",
    "            outcome.append({'model':model.__name__,'block':i,'metric':'r2s','value':r2s})\n",
    "            outcome.append({'model':model.__name__,'block':i,'metric':'rmse','value':rmse})\n",
    "                \n",
    "        print () \n",
    "        \n",
    "    return outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation: generating test and train for i=30\n",
      "validation: testing model constant_model\n",
      "validation: testing model previous_value_model\n",
      "validation: testing model lin_model\n",
      "validation: testing model lin_model_with_feature_norm\n",
      "validation: testing model lightgbm_model\n",
      "\n",
      "validation: generating test and train for i=31\n",
      "validation: testing model constant_model\n",
      "validation: testing model previous_value_model\n",
      "validation: testing model lin_model\n",
      "validation: testing model lin_model_with_feature_norm\n",
      "validation: testing model lightgbm_model\n",
      "\n",
      "validation: generating test and train for i=32\n",
      "validation: testing model constant_model\n",
      "validation: testing model previous_value_model\n",
      "validation: testing model lin_model\n",
      "validation: testing model lin_model_with_feature_norm\n",
      "validation: testing model lightgbm_model\n",
      "\n",
      "validation: generating test and train for i=33\n",
      "validation: testing model constant_model\n",
      "validation: testing model previous_value_model\n",
      "validation: testing model lin_model\n",
      "validation: testing model lin_model_with_feature_norm\n",
      "validation: testing model lightgbm_model\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>metric</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>constant_model</td>\n",
       "      <td>r2s</td>\n",
       "      <td>-0.000926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>constant_model</td>\n",
       "      <td>rmse</td>\n",
       "      <td>1.086481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lightgbm_model</td>\n",
       "      <td>r2s</td>\n",
       "      <td>0.370840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lightgbm_model</td>\n",
       "      <td>rmse</td>\n",
       "      <td>0.862635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lin_model</td>\n",
       "      <td>r2s</td>\n",
       "      <td>0.307244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>lin_model</td>\n",
       "      <td>rmse</td>\n",
       "      <td>0.905361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>lin_model_with_feature_norm</td>\n",
       "      <td>r2s</td>\n",
       "      <td>0.307244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>lin_model_with_feature_norm</td>\n",
       "      <td>rmse</td>\n",
       "      <td>0.905361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>previous_value_model</td>\n",
       "      <td>r2s</td>\n",
       "      <td>0.138526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>previous_value_model</td>\n",
       "      <td>rmse</td>\n",
       "      <td>1.008575</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         model metric     value\n",
       "0               constant_model    r2s -0.000926\n",
       "1               constant_model   rmse  1.086481\n",
       "2               lightgbm_model    r2s  0.370840\n",
       "3               lightgbm_model   rmse  0.862635\n",
       "4                    lin_model    r2s  0.307244\n",
       "5                    lin_model   rmse  0.905361\n",
       "6  lin_model_with_feature_norm    r2s  0.307244\n",
       "7  lin_model_with_feature_norm   rmse  0.905361\n",
       "8         previous_value_model    r2s  0.138526\n",
       "9         previous_value_model   rmse  1.008575"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# resut = validate([constant_model,previous_value_model,lin_model,xgboost_model])\n",
    "resut = validate([constant_model,previous_value_model,lin_model, lin_model_with_feature_norm, lightgbm_model])\n",
    "\n",
    "pd.DataFrame(resut).groupby(['model','metric'],as_index=False).agg({'value':'mean'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation:\n",
    "\n",
    "model \tmetric \tvalue\n",
    "0 \tconstant_model \tr2s \t-0.000926\n",
    "1 \tconstant_model \trmse \t1.086481\n",
    "2 \tlin_model \tr2s \t0.307244\n",
    "3 \tlin_model \trmse \t0.905361\n",
    "4 \tprevious_value_model \tr2s \t0.138526\n",
    "5 \tprevious_value_model \trmse \t1.008575\n",
    "6 \txgboost_model \tr2s \t0.358721\n",
    "7 \txgboost_model \trmse \t0.870930\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Seems local validation somehow corelates with public leaderboard </b>\n",
    "\n",
    "|Name|Score|Local score|Model|Comment|\n",
    "|----|-----|-----------|-----|-------|\n",
    "|submition_2019_06_03_09_29.csv.gz|1.16777|1.008575|Last month baseline||\n",
    "|submition_lin_model_2019_12_02_13_50.csv.gz|1.96182||simple linear model with 2 month shifts and with clipping 0-300|wrong cliipng|\n",
    "|submition_lin_model_2019_12_02_13_56.csv.gz|4.34576||simple linear model with 2 month shifts with clipping removed|no clipping|\n",
    "|submition_lin_model_2019_12_02_15_39.csv.gz|1.08014|0.905361|simple linear model, more with proper clipping|proper clipping apllied|\n",
    "|submition_xgboost_model_2019_12_03_15_43.csv.gz|1.02016|0.870930|simple xgboost without any parameters tuned|\n",
    "|submition_lightgbm_model_2019_12_04_05_53.csv.gz|**1.00715**|0.862635|simple light gbm without any parameters tuned|\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submition_lightgbm_model_2019_12_05_06_36.csv.gz prepared\n"
     ]
    }
   ],
   "source": [
    "def prepare_submit(model):\n",
    "    \n",
    "    (train_groupped_with_shifted, test_set_with_shifted, fit_col) = \\\n",
    "            generate_shifted_features(transactions,test_set)\n",
    "    \n",
    "    predictions = model(train_groupped_with_shifted, test_set_with_shifted,fit_col)\n",
    "    test_set_with_shifted ['predictions'] = predictions\n",
    "    \n",
    "    # adjust types\n",
    "    test_set_with_shifted.ID = test_set_with_shifted.ID.astype(int)\n",
    "    test_set_with_shifted.rename(columns={'predictions':'item_cnt_month'},inplace=True)\n",
    "\n",
    "    filename = 'submition_{}_{}.csv.gz'.format(model.__name__,time.strftime('%Y_%m_%d_%H_%M',time.localtime()))\n",
    "    test_set_with_shifted[['ID','item_cnt_month']].to_csv(filename,index=False)\n",
    "    print (filename + ' prepared')\n",
    "    \n",
    "    \n",
    "prepare_submit(lightgbm_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation: TODO\n",
    "1. From the task - Type of public/private split is identified\n",
    "2. Compare for more complex model which metric better correlates with lederboard - rmse or r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # out of functions code to test model\n",
    "\n",
    "# train_transactions = transactions[transactions.date_block_num<32]\n",
    "# test_transactions = transactions[transactions.date_block_num==33]\n",
    "\n",
    "# test_set = pd.DataFrame(cartesian_product(test_transactions.shop_id.unique(), \n",
    "#                                test_transactions.item_id.unique()),columns=['shop_id','item_id'])\n",
    "\n",
    "# true_values = test_set.merge ( \\\n",
    "#     test_transactions.groupby(['shop_id','item_id'],as_index=False).agg({'item_cnt_day':'sum'}), \\\n",
    "#     how = 'left' ).fillna(0)\n",
    "\n",
    "# (train_groupped_with_shifted, test_set_with_shifted, fit_col) = \\\n",
    "#     generate_shifted_features(train_transactions,true_values[['shop_id','item_id']])\n",
    "\n",
    "# train_set = train_groupped_with_shifted\n",
    "# test_set = test_set_with_shifted\n",
    "\n",
    "# # predictions = lin_model(train_groupped_with_shifted, test_set_with_shifted,fit_col)\n",
    "# # rmse = np.sqrt(mean_squared_error(true_values['item_cnt_day'].clip(lower=0.0, upper =20.0).values, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # \n",
    "# xgb_model = xgboost.XGBRegressor(n_jobs=4,objective='reg:squarederror',verbosity=2)\n",
    "# xgb_model.fit(train_groupped_with_shifted[fit_col],train_groupped_with_shifted['target'])\n",
    "# predictions = xgb_model.predict(test_set_with_shifted[fit_col])\n",
    "# rmse = np.sqrt(mean_squared_error(true_values['item_cnt_day'].clip(lower=0.0, upper =20.0).values, predictions.clip(min=0.0, max =20.0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering\n",
    "\n",
    "1. First let's do obvious thing suggested in week4 - adding as features 1-2-3-4 month back sales, pass if over model and see what will happen to metrics, local validation and submitted score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "hw_version": "1.0.0",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
